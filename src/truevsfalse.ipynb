{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><h1> Data Science Project </h1></div>\n",
    "<div align=\"center\"><h2> Classification of assertions according to their veracity values ( automatic fact-checking ) </h2></div>\n",
    "<h2>Group member</h2>\n",
    "<ul>\n",
    "    <li>Meriem AMERAOUI</li>\n",
    "    <li>Dounia BELABIOD</li>\n",
    "    <li>Jihene BOUHLEL</li>\n",
    "    <li>Bahaa Eddine NIL</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" align=\"center\">\n",
    "    <h1>\n",
    "        Basics\n",
    "    </h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "import inflect\n",
    "import re\n",
    "import nltk\n",
    "import contractions\n",
    "\n",
    "from functools import reduce\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.utils import resample\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Cleaning the text\n",
    "def remove_non_ascii(words):\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = unicodedata.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "        new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def to_lowercase(words):\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = word.lower()\n",
    "        new_words.append(new_word) \n",
    "    return new_words\n",
    "\n",
    "def remove_punctuation(words):\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = re.sub(r'[^\\w\\s]', '', word)\n",
    "        if new_word != '':\n",
    "            new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def replace_numbers(words):\n",
    "    p = inflect.engine()\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word.isdigit():\n",
    "            new_word = p.number_to_words(word)\n",
    "            new_words.append(new_word)\n",
    "        else:\n",
    "            new_words.append(word)\n",
    "    return new_words\n",
    "\n",
    "def remove_stopwords(words):\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word not in stopwords.words('english'):\n",
    "            new_words.append(word)\n",
    "    return new_words\n",
    "\n",
    "def separate_letter_number(words):\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        nw = re.findall('\\d+|\\D+', word)\n",
    "        new_words.append(nw)\n",
    "    new_words = reduce(lambda x,y: x+y,new_words)\n",
    "    return new_words\n",
    "\n",
    "def replace_contractions(text):\n",
    "    return \n",
    "\n",
    "def normalize(words):\n",
    "    words = remove_non_ascii(words)\n",
    "    words = to_lowercase(words)\n",
    "    #words = separate_letter_number(words)\n",
    "    words = replace_numbers(words)\n",
    "    words = remove_punctuation(words)\n",
    "    words = remove_stopwords(words)\n",
    "    return words\n",
    "\n",
    "def clean_text(text):\n",
    "    porterStemmer = PorterStemmer()\n",
    "    lancasterStemmer = LancasterStemmer()\n",
    "    wordNetLemmatizer = WordNetLemmatizer()\n",
    "    #tokens = word_tokenize(contractions.fix(text))\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = normalize(tokens)\n",
    "    #tokens = [porterStemmer.stem(word) for word in tokens]\n",
    "    #tokens = [lancasterStemmer.stem(word) for word in tokens]\n",
    "    #tokens = [wordNetLemmatizer.lemmatize(word, pos = 'v') for word in tokens]\n",
    "    text=\"\".join([\" \"+i for i in tokens]).strip()\n",
    "    return text\n",
    "\n",
    "# Up-sampling & Down-sampling\n",
    "def sampling(df_func, *args, **kwargs):\n",
    "    sampling_type = kwargs.get(\"sample\", None)\n",
    "    if(sampling_type not in ['up', 'down']):\n",
    "        print('Please select somthing in [\\'up\\', \\'down\\']')\n",
    "\n",
    "    else:\n",
    "        majority = df_func[df_func.RatingName == df_func['RatingName'].value_counts()\n",
    "                           .index.tolist()[0]].reset_index(drop = True)\n",
    "        minority = df_func[df_func.RatingName == df_func['RatingName'].value_counts()\n",
    "                           .index.tolist()[-1]].reset_index(drop = True)\n",
    "\n",
    "        if(sampling_type == 'up'):\n",
    "            df_func = resample(minority, replace = True, n_samples = df_func['RatingName']\n",
    "                               .value_counts().tolist()[0], random_state = 123)\n",
    "            df_func = pd.concat([majority, df_func]).sample(frac = 1).reset_index(drop = True)\n",
    "\n",
    "        if(sampling_type == 'down'):\n",
    "            df_func = resample(majority, replace=False, n_samples=df_func['RatingName']\n",
    "                               .value_counts().tolist()[-1], random_state=123) \n",
    "            df_func = pd.concat([df_func, minority]).reset_index(drop = True)\n",
    "\n",
    "        return df_func\n",
    "\n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "except LookupError:\n",
    "    nltk.download('punkt')\n",
    "\n",
    "try:\n",
    "    nltk.data.find('corpora/stopwords')\n",
    "except LookupError:\n",
    "    nltk.download('stopwords')\n",
    "    \n",
    "try:\n",
    "    nltk.data.find('corpora/wordnet')\n",
    "except LookupError:\n",
    "    nltk.download('wordnet')\n",
    "\n",
    "try:\n",
    "    nltk.data.find('taggers/averaged_perceptron_tagger')\n",
    "except LookupError:\n",
    "    nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" align=\"center\">\n",
    "    <h1>\n",
    "        Reading data\n",
    "    </h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/generated.csv', sep = ';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" align=\"center\">\n",
    "    <h1>\n",
    "        Pre-processing\n",
    "    </h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>RatingName</th>\n",
       "      <th>Author</th>\n",
       "      <th>Headline</th>\n",
       "      <th>NamedEntitiesClaim</th>\n",
       "      <th>NamedEntitiesArticle</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Malia Obama cashed a $1.2 million tax refund c...</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Did Malia Obama Cash a $1.2 Million Check?</td>\n",
       "      <td>Facebook,Fan Fiction,Junk News,Malia Obama,Sno...</td>\n",
       "      <td>Malia Obama</td>\n",
       "      <td>NaN</td>\n",
       "      <td>truthorfiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>High diver is saved from jumping into a draine...</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>High Diver Saved By Cross</td>\n",
       "      <td>Cincinnati Post,Islam,Scripture lesson,Univers...</td>\n",
       "      <td>shadow on the wall</td>\n",
       "      <td>ASP Article</td>\n",
       "      <td>snopes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>'And the revenue generated by drilling off Vir...</td>\n",
       "      <td>MIXTURE</td>\n",
       "      <td>Jim Moran</td>\n",
       "      <td>Moran says drilling off Virginia's coast will ...</td>\n",
       "      <td>Alaska,American Petroleum Institute,Atlantic O...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Energy,State Finances</td>\n",
       "      <td>politifact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Health insurance companies pay CEOs $24 millio...</td>\n",
       "      <td>MIXTURE</td>\n",
       "      <td>Health Care for America Now</td>\n",
       "      <td>Health care advocacy group blasts insurers for...</td>\n",
       "      <td>Aetna,Assurant,Bloomberg News,Cigna,Coventry H...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Corporations,Health Care</td>\n",
       "      <td>politifact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Ted Cruz said that veterans should start selli...</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Ted Cruz: Vets Should Sell Cookies for Funding...</td>\n",
       "      <td>David Nelson,James Morrison,John Scalzi,Republ...</td>\n",
       "      <td>Ted Cruz</td>\n",
       "      <td>ASP Article, Not Necessarily The News</td>\n",
       "      <td>snopes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text RatingName  \\\n",
       "0  Malia Obama cashed a $1.2 million tax refund c...      OTHER   \n",
       "1  High diver is saved from jumping into a draine...      OTHER   \n",
       "2  'And the revenue generated by drilling off Vir...    MIXTURE   \n",
       "3  Health insurance companies pay CEOs $24 millio...    MIXTURE   \n",
       "4  Ted Cruz said that veterans should start selli...      FALSE   \n",
       "\n",
       "                        Author  \\\n",
       "0                      Unknown   \n",
       "1                      Unknown   \n",
       "2                    Jim Moran   \n",
       "3  Health Care for America Now   \n",
       "4                      Unknown   \n",
       "\n",
       "                                            Headline  \\\n",
       "0         Did Malia Obama Cash a $1.2 Million Check?   \n",
       "1                          High Diver Saved By Cross   \n",
       "2  Moran says drilling off Virginia's coast will ...   \n",
       "3  Health care advocacy group blasts insurers for...   \n",
       "4  Ted Cruz: Vets Should Sell Cookies for Funding...   \n",
       "\n",
       "                                  NamedEntitiesClaim NamedEntitiesArticle  \\\n",
       "0  Facebook,Fan Fiction,Junk News,Malia Obama,Sno...          Malia Obama   \n",
       "1  Cincinnati Post,Islam,Scripture lesson,Univers...   shadow on the wall   \n",
       "2  Alaska,American Petroleum Institute,Atlantic O...                  NaN   \n",
       "3  Aetna,Assurant,Bloomberg News,Cigna,Coventry H...                  NaN   \n",
       "4  David Nelson,James Morrison,John Scalzi,Republ...             Ted Cruz   \n",
       "\n",
       "                                Keywords          Source  \n",
       "0                                    NaN  truthorfiction  \n",
       "1                            ASP Article          snopes  \n",
       "2                  Energy,State Finances      politifact  \n",
       "3               Corporations,Health Care      politifact  \n",
       "4  ASP Article, Not Necessarily The News          snopes  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = df.drop(['ID', 'Date', 'TruthRating', 'SourceURL', 'Link', 'Language'], axis = 1)\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove unnecessary rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>RatingName</th>\n",
       "      <th>Author</th>\n",
       "      <th>Headline</th>\n",
       "      <th>NamedEntitiesClaim</th>\n",
       "      <th>NamedEntitiesArticle</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Ted Cruz said that veterans should start selli...</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Ted Cruz: Vets Should Sell Cookies for Funding...</td>\n",
       "      <td>David Nelson,James Morrison,John Scalzi,Republ...</td>\n",
       "      <td>Ted Cruz</td>\n",
       "      <td>ASP Article, Not Necessarily The News</td>\n",
       "      <td>snopes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>'The Georgia Lottery Corp. has only once in th...</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>Allie McCullen</td>\n",
       "      <td>Luck runs out for student on lottery claim</td>\n",
       "      <td>Georgia Lottery,HOPE scholarship,Mega Millions...</td>\n",
       "      <td>Georgia Lottery,HOPE scholarship</td>\n",
       "      <td>Education</td>\n",
       "      <td>politifact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Panda Express will be celebrating its 15th ann...</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Panda Express 15th Anniversary Offer</td>\n",
       "      <td>Los Angeles Times,Panda Express,Panda Inn,Wend...</td>\n",
       "      <td>Panda Express</td>\n",
       "      <td>ASP Article, something for nothing</td>\n",
       "      <td>snopes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>'There’s no money' for Planned Parenthood in t...</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>Tom Cole</td>\n",
       "      <td>Is there Planned Parenthood funding in the bil...</td>\n",
       "      <td>Children’s Health Insurance Program,Fox News S...</td>\n",
       "      <td>Planned Parenthood</td>\n",
       "      <td>Abortion,Congress,Congressional Rules,Federal ...</td>\n",
       "      <td>politifact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>'In 2010 alone, 1,270 infants were reported to...</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>Americans United for Life</td>\n",
       "      <td>Americans United for Life says 1,270 babies di...</td>\n",
       "      <td>Alan Guttmacher Institute,Americans United for...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Abortion</td>\n",
       "      <td>politifact</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Text RatingName  \\\n",
       "4   Ted Cruz said that veterans should start selli...      FALSE   \n",
       "7   'The Georgia Lottery Corp. has only once in th...      FALSE   \n",
       "9   Panda Express will be celebrating its 15th ann...      FALSE   \n",
       "10  'There’s no money' for Planned Parenthood in t...       TRUE   \n",
       "11  'In 2010 alone, 1,270 infants were reported to...      FALSE   \n",
       "\n",
       "                       Author  \\\n",
       "4                     Unknown   \n",
       "7              Allie McCullen   \n",
       "9                     Unknown   \n",
       "10                   Tom Cole   \n",
       "11  Americans United for Life   \n",
       "\n",
       "                                             Headline  \\\n",
       "4   Ted Cruz: Vets Should Sell Cookies for Funding...   \n",
       "7          Luck runs out for student on lottery claim   \n",
       "9                Panda Express 15th Anniversary Offer   \n",
       "10  Is there Planned Parenthood funding in the bil...   \n",
       "11  Americans United for Life says 1,270 babies di...   \n",
       "\n",
       "                                   NamedEntitiesClaim  \\\n",
       "4   David Nelson,James Morrison,John Scalzi,Republ...   \n",
       "7   Georgia Lottery,HOPE scholarship,Mega Millions...   \n",
       "9   Los Angeles Times,Panda Express,Panda Inn,Wend...   \n",
       "10  Children’s Health Insurance Program,Fox News S...   \n",
       "11  Alan Guttmacher Institute,Americans United for...   \n",
       "\n",
       "                NamedEntitiesArticle  \\\n",
       "4                           Ted Cruz   \n",
       "7   Georgia Lottery,HOPE scholarship   \n",
       "9                      Panda Express   \n",
       "10                Planned Parenthood   \n",
       "11                               NaN   \n",
       "\n",
       "                                             Keywords      Source  \n",
       "4               ASP Article, Not Necessarily The News      snopes  \n",
       "7                                           Education  politifact  \n",
       "9                  ASP Article, something for nothing      snopes  \n",
       "10  Abortion,Congress,Congressional Rules,Federal ...  politifact  \n",
       "11                                           Abortion  politifact  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Deleting claims with OTHER é MIXTURE RatingName\n",
    "df = df[df.RatingName != 'OTHER']\n",
    "df = df[df.RatingName != 'MIXTURE']\n",
    "\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replacing \"Unknown\" & NaN by \"Inconnue\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>RatingName</th>\n",
       "      <th>Author</th>\n",
       "      <th>Headline</th>\n",
       "      <th>NamedEntitiesClaim</th>\n",
       "      <th>NamedEntitiesArticle</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Ted Cruz said that veterans should start selli...</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>Inconnue</td>\n",
       "      <td>Ted Cruz: Vets Should Sell Cookies for Funding...</td>\n",
       "      <td>David Nelson,James Morrison,John Scalzi,Republ...</td>\n",
       "      <td>Ted Cruz</td>\n",
       "      <td>ASP Article, Not Necessarily The News</td>\n",
       "      <td>snopes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>'The Georgia Lottery Corp. has only once in th...</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>Allie McCullen</td>\n",
       "      <td>Luck runs out for student on lottery claim</td>\n",
       "      <td>Georgia Lottery,HOPE scholarship,Mega Millions...</td>\n",
       "      <td>Georgia Lottery,HOPE scholarship</td>\n",
       "      <td>Education</td>\n",
       "      <td>politifact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Panda Express will be celebrating its 15th ann...</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>Inconnue</td>\n",
       "      <td>Panda Express 15th Anniversary Offer</td>\n",
       "      <td>Los Angeles Times,Panda Express,Panda Inn,Wend...</td>\n",
       "      <td>Panda Express</td>\n",
       "      <td>ASP Article, something for nothing</td>\n",
       "      <td>snopes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>'There’s no money' for Planned Parenthood in t...</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>Tom Cole</td>\n",
       "      <td>Is there Planned Parenthood funding in the bil...</td>\n",
       "      <td>Children’s Health Insurance Program,Fox News S...</td>\n",
       "      <td>Planned Parenthood</td>\n",
       "      <td>Abortion,Congress,Congressional Rules,Federal ...</td>\n",
       "      <td>politifact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>'In 2010 alone, 1,270 infants were reported to...</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>Americans United for Life</td>\n",
       "      <td>Americans United for Life says 1,270 babies di...</td>\n",
       "      <td>Alan Guttmacher Institute,Americans United for...</td>\n",
       "      <td>Inconnue</td>\n",
       "      <td>Abortion</td>\n",
       "      <td>politifact</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Text RatingName  \\\n",
       "4   Ted Cruz said that veterans should start selli...      FALSE   \n",
       "7   'The Georgia Lottery Corp. has only once in th...      FALSE   \n",
       "9   Panda Express will be celebrating its 15th ann...      FALSE   \n",
       "10  'There’s no money' for Planned Parenthood in t...       TRUE   \n",
       "11  'In 2010 alone, 1,270 infants were reported to...      FALSE   \n",
       "\n",
       "                       Author  \\\n",
       "4                    Inconnue   \n",
       "7              Allie McCullen   \n",
       "9                    Inconnue   \n",
       "10                   Tom Cole   \n",
       "11  Americans United for Life   \n",
       "\n",
       "                                             Headline  \\\n",
       "4   Ted Cruz: Vets Should Sell Cookies for Funding...   \n",
       "7          Luck runs out for student on lottery claim   \n",
       "9                Panda Express 15th Anniversary Offer   \n",
       "10  Is there Planned Parenthood funding in the bil...   \n",
       "11  Americans United for Life says 1,270 babies di...   \n",
       "\n",
       "                                   NamedEntitiesClaim  \\\n",
       "4   David Nelson,James Morrison,John Scalzi,Republ...   \n",
       "7   Georgia Lottery,HOPE scholarship,Mega Millions...   \n",
       "9   Los Angeles Times,Panda Express,Panda Inn,Wend...   \n",
       "10  Children’s Health Insurance Program,Fox News S...   \n",
       "11  Alan Guttmacher Institute,Americans United for...   \n",
       "\n",
       "                NamedEntitiesArticle  \\\n",
       "4                           Ted Cruz   \n",
       "7   Georgia Lottery,HOPE scholarship   \n",
       "9                      Panda Express   \n",
       "10                Planned Parenthood   \n",
       "11                          Inconnue   \n",
       "\n",
       "                                             Keywords      Source  \n",
       "4               ASP Article, Not Necessarily The News      snopes  \n",
       "7                                           Education  politifact  \n",
       "9                  ASP Article, something for nothing      snopes  \n",
       "10  Abortion,Congress,Congressional Rules,Federal ...  politifact  \n",
       "11                                           Abortion  politifact  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for column in df.columns:\n",
    "    df[column].replace(to_replace = 'Unknown', value = 'Inconnue', inplace = True)\n",
    "    df[column].replace(np.NaN, 'Inconnue', inplace = True)\n",
    "    \n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>RatingName</th>\n",
       "      <th>Author</th>\n",
       "      <th>Headline</th>\n",
       "      <th>NamedEntitiesClaim</th>\n",
       "      <th>NamedEntitiesArticle</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ted cruz said veterans start selling cookies o...</td>\n",
       "      <td>false</td>\n",
       "      <td>inconnue</td>\n",
       "      <td>ted cruz vets sell cookies funding like girl s...</td>\n",
       "      <td>david nelson james morrison john scalzi republ...</td>\n",
       "      <td>ted cruz</td>\n",
       "      <td>asp article necessarily news</td>\n",
       "      <td>snopes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>georgia lottery corp past sixteen years paid a...</td>\n",
       "      <td>false</td>\n",
       "      <td>allie mccullen</td>\n",
       "      <td>luck runs student lottery claim</td>\n",
       "      <td>georgia lottery hope scholarship mega millions...</td>\n",
       "      <td>georgia lottery hope scholarship</td>\n",
       "      <td>education</td>\n",
       "      <td>politifact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>panda express celebrating 15th anniversary off...</td>\n",
       "      <td>false</td>\n",
       "      <td>inconnue</td>\n",
       "      <td>panda express 15th anniversary offer</td>\n",
       "      <td>los angeles times panda express panda inn wend...</td>\n",
       "      <td>panda express</td>\n",
       "      <td>asp article something nothing</td>\n",
       "      <td>snopes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>money planned parenthood bill would keep gover...</td>\n",
       "      <td>true</td>\n",
       "      <td>tom cole</td>\n",
       "      <td>planned parenthood funding bill stops governme...</td>\n",
       "      <td>children health insurance program fox news sun...</td>\n",
       "      <td>planned parenthood</td>\n",
       "      <td>abortion congress congressional rules federal ...</td>\n",
       "      <td>politifact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>two thousand and ten alone 1270 infants report...</td>\n",
       "      <td>false</td>\n",
       "      <td>americans united life</td>\n",
       "      <td>americans united life says 1270 babies died at...</td>\n",
       "      <td>alan guttmacher institute americans united lif...</td>\n",
       "      <td>inconnue</td>\n",
       "      <td>abortion</td>\n",
       "      <td>politifact</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Text RatingName  \\\n",
       "4   ted cruz said veterans start selling cookies o...      false   \n",
       "7   georgia lottery corp past sixteen years paid a...      false   \n",
       "9   panda express celebrating 15th anniversary off...      false   \n",
       "10  money planned parenthood bill would keep gover...       true   \n",
       "11  two thousand and ten alone 1270 infants report...      false   \n",
       "\n",
       "                   Author                                           Headline  \\\n",
       "4                inconnue  ted cruz vets sell cookies funding like girl s...   \n",
       "7          allie mccullen                    luck runs student lottery claim   \n",
       "9                inconnue               panda express 15th anniversary offer   \n",
       "10               tom cole  planned parenthood funding bill stops governme...   \n",
       "11  americans united life  americans united life says 1270 babies died at...   \n",
       "\n",
       "                                   NamedEntitiesClaim  \\\n",
       "4   david nelson james morrison john scalzi republ...   \n",
       "7   georgia lottery hope scholarship mega millions...   \n",
       "9   los angeles times panda express panda inn wend...   \n",
       "10  children health insurance program fox news sun...   \n",
       "11  alan guttmacher institute americans united lif...   \n",
       "\n",
       "                NamedEntitiesArticle  \\\n",
       "4                           ted cruz   \n",
       "7   georgia lottery hope scholarship   \n",
       "9                      panda express   \n",
       "10                planned parenthood   \n",
       "11                          inconnue   \n",
       "\n",
       "                                             Keywords      Source  \n",
       "4                        asp article necessarily news      snopes  \n",
       "7                                           education  politifact  \n",
       "9                       asp article something nothing      snopes  \n",
       "10  abortion congress congressional rules federal ...  politifact  \n",
       "11                                           abortion  politifact  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>RatingName</th>\n",
       "      <th>Author</th>\n",
       "      <th>Headline</th>\n",
       "      <th>NamedEntitiesClaim</th>\n",
       "      <th>NamedEntitiesArticle</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>488</td>\n",
       "      <td>488</td>\n",
       "      <td>488</td>\n",
       "      <td>488</td>\n",
       "      <td>488</td>\n",
       "      <td>488</td>\n",
       "      <td>488</td>\n",
       "      <td>488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>unique</td>\n",
       "      <td>488</td>\n",
       "      <td>2</td>\n",
       "      <td>156</td>\n",
       "      <td>488</td>\n",
       "      <td>488</td>\n",
       "      <td>300</td>\n",
       "      <td>358</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>top</td>\n",
       "      <td>striped mittenfish change sex turning entire b...</td>\n",
       "      <td>false</td>\n",
       "      <td>inconnue</td>\n",
       "      <td>seven hollywood liberal heroes arrested oscar ...</td>\n",
       "      <td>two thousand and nine college basketball invit...</td>\n",
       "      <td>inconnue</td>\n",
       "      <td>inconnue</td>\n",
       "      <td>snopes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>freq</td>\n",
       "      <td>1</td>\n",
       "      <td>358</td>\n",
       "      <td>282</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>28</td>\n",
       "      <td>261</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Text RatingName  \\\n",
       "count                                                 488        488   \n",
       "unique                                                488          2   \n",
       "top     striped mittenfish change sex turning entire b...      false   \n",
       "freq                                                    1        358   \n",
       "\n",
       "          Author                                           Headline  \\\n",
       "count        488                                                488   \n",
       "unique       156                                                488   \n",
       "top     inconnue  seven hollywood liberal heroes arrested oscar ...   \n",
       "freq         282                                                  1   \n",
       "\n",
       "                                       NamedEntitiesClaim  \\\n",
       "count                                                 488   \n",
       "unique                                                488   \n",
       "top     two thousand and nine college basketball invit...   \n",
       "freq                                                    1   \n",
       "\n",
       "       NamedEntitiesArticle  Keywords  Source  \n",
       "count                   488       488     488  \n",
       "unique                  300       358       5  \n",
       "top                inconnue  inconnue  snopes  \n",
       "freq                    163        28     261  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfClean = df.copy()\n",
    "for column in dfClean.columns:\n",
    "    dfClean[column] = dfClean[column].apply(lambda x: clean_text(x))\n",
    "\n",
    "display(dfClean.head())\n",
    "display(dfClean.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>RatingName</th>\n",
       "      <th>Author</th>\n",
       "      <th>Headline</th>\n",
       "      <th>NamedEntitiesClaim</th>\n",
       "      <th>NamedEntitiesArticle</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>photographs show furniture floating automobile...</td>\n",
       "      <td>true</td>\n",
       "      <td>inconnue</td>\n",
       "      <td>wood art</td>\n",
       "      <td>craftsmanship museum ferrari ferrari f50 internet</td>\n",
       "      <td>inconnue</td>\n",
       "      <td>asp article stephanie cegielski</td>\n",
       "      <td>snopes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>photograph show aftermath bombing vatican city</td>\n",
       "      <td>false</td>\n",
       "      <td>inconnue</td>\n",
       "      <td>bombing take place vatican city</td>\n",
       "      <td>islam quran ramadan twitter vatican city vigil...</td>\n",
       "      <td>vatican city</td>\n",
       "      <td>bombing fire smoke vatican</td>\n",
       "      <td>snopes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>actor gary sinise posted witty retort hillary ...</td>\n",
       "      <td>false</td>\n",
       "      <td>inconnue</td>\n",
       "      <td>gary sinise tweets hillary clinton guns</td>\n",
       "      <td>facebook gary sinise hillary clinton twitter g...</td>\n",
       "      <td>gary sinise hillary clinton gun control</td>\n",
       "      <td>gary sinise gun control hillary clinton</td>\n",
       "      <td>snopes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>right georgia nearly one three leaving prisons...</td>\n",
       "      <td>true</td>\n",
       "      <td>nathan deal</td>\n",
       "      <td>deal makes arresting claim georgia prisons</td>\n",
       "      <td>medicaid nathan deal politifact chew recidivism</td>\n",
       "      <td>inconnue</td>\n",
       "      <td>criminal justice</td>\n",
       "      <td>politifact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>health insurance companies costs four percent ...</td>\n",
       "      <td>true</td>\n",
       "      <td>america health insurance plans</td>\n",
       "      <td>health insurers get small percentage overall h...</td>\n",
       "      <td>america health insurance plans centers medicar...</td>\n",
       "      <td>health insurance</td>\n",
       "      <td>health care</td>\n",
       "      <td>politifact</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text RatingName  \\\n",
       "0  photographs show furniture floating automobile...       true   \n",
       "1     photograph show aftermath bombing vatican city      false   \n",
       "2  actor gary sinise posted witty retort hillary ...      false   \n",
       "3  right georgia nearly one three leaving prisons...       true   \n",
       "4  health insurance companies costs four percent ...       true   \n",
       "\n",
       "                           Author  \\\n",
       "0                        inconnue   \n",
       "1                        inconnue   \n",
       "2                        inconnue   \n",
       "3                     nathan deal   \n",
       "4  america health insurance plans   \n",
       "\n",
       "                                            Headline  \\\n",
       "0                                           wood art   \n",
       "1                    bombing take place vatican city   \n",
       "2            gary sinise tweets hillary clinton guns   \n",
       "3         deal makes arresting claim georgia prisons   \n",
       "4  health insurers get small percentage overall h...   \n",
       "\n",
       "                                  NamedEntitiesClaim  \\\n",
       "0  craftsmanship museum ferrari ferrari f50 internet   \n",
       "1  islam quran ramadan twitter vatican city vigil...   \n",
       "2  facebook gary sinise hillary clinton twitter g...   \n",
       "3    medicaid nathan deal politifact chew recidivism   \n",
       "4  america health insurance plans centers medicar...   \n",
       "\n",
       "                      NamedEntitiesArticle  \\\n",
       "0                                 inconnue   \n",
       "1                             vatican city   \n",
       "2  gary sinise hillary clinton gun control   \n",
       "3                                 inconnue   \n",
       "4                         health insurance   \n",
       "\n",
       "                                  Keywords      Source  \n",
       "0          asp article stephanie cegielski      snopes  \n",
       "1               bombing fire smoke vatican      snopes  \n",
       "2  gary sinise gun control hillary clinton      snopes  \n",
       "3                         criminal justice  politifact  \n",
       "4                              health care  politifact  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>RatingName</th>\n",
       "      <th>Author</th>\n",
       "      <th>Headline</th>\n",
       "      <th>NamedEntitiesClaim</th>\n",
       "      <th>NamedEntitiesArticle</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>716</td>\n",
       "      <td>716</td>\n",
       "      <td>716</td>\n",
       "      <td>716</td>\n",
       "      <td>716</td>\n",
       "      <td>716</td>\n",
       "      <td>716</td>\n",
       "      <td>716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>unique</td>\n",
       "      <td>481</td>\n",
       "      <td>2</td>\n",
       "      <td>154</td>\n",
       "      <td>481</td>\n",
       "      <td>481</td>\n",
       "      <td>298</td>\n",
       "      <td>355</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>top</td>\n",
       "      <td>says people signed recall petitions wisconsin ...</td>\n",
       "      <td>true</td>\n",
       "      <td>inconnue</td>\n",
       "      <td>wisconsin tea party leader says democrathired ...</td>\n",
       "      <td>democrat eagle river jim holperin politifact r...</td>\n",
       "      <td>inconnue</td>\n",
       "      <td>inconnue</td>\n",
       "      <td>politifact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>freq</td>\n",
       "      <td>11</td>\n",
       "      <td>358</td>\n",
       "      <td>369</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>278</td>\n",
       "      <td>38</td>\n",
       "      <td>345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Text RatingName  \\\n",
       "count                                                 716        716   \n",
       "unique                                                481          2   \n",
       "top     says people signed recall petitions wisconsin ...       true   \n",
       "freq                                                   11        358   \n",
       "\n",
       "          Author                                           Headline  \\\n",
       "count        716                                                716   \n",
       "unique       154                                                481   \n",
       "top     inconnue  wisconsin tea party leader says democrathired ...   \n",
       "freq         369                                                 11   \n",
       "\n",
       "                                       NamedEntitiesClaim  \\\n",
       "count                                                 716   \n",
       "unique                                                481   \n",
       "top     democrat eagle river jim holperin politifact r...   \n",
       "freq                                                   11   \n",
       "\n",
       "       NamedEntitiesArticle  Keywords      Source  \n",
       "count                   716       716         716  \n",
       "unique                  298       355           5  \n",
       "top                inconnue  inconnue  politifact  \n",
       "freq                    278        38         345  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfCleanUpsample = sampling(dfClean, sample = 'up')\n",
    "display(dfCleanUpsample.head())\n",
    "display(dfCleanUpsample.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>RatingName</th>\n",
       "      <th>Author</th>\n",
       "      <th>Headline</th>\n",
       "      <th>NamedEntitiesClaim</th>\n",
       "      <th>NamedEntitiesArticle</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>says 74 percent smallbusiness people believe o...</td>\n",
       "      <td>false</td>\n",
       "      <td>larry elder</td>\n",
       "      <td>claim nt pass examination</td>\n",
       "      <td>cnn lemon gallup poll larry elder marco rubio ...</td>\n",
       "      <td>bad</td>\n",
       "      <td>health care</td>\n",
       "      <td>politifact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>giant asteroid expected hit earth july two tho...</td>\n",
       "      <td>false</td>\n",
       "      <td>inconnue</td>\n",
       "      <td>scientists say giant asteroid could hit earth ...</td>\n",
       "      <td>asteroid columbia university facebook asteroid...</td>\n",
       "      <td>asteroid</td>\n",
       "      <td>asteroid clickbait</td>\n",
       "      <td>snopes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>image shows radioactive seepage spreading acro...</td>\n",
       "      <td>false</td>\n",
       "      <td>inconnue</td>\n",
       "      <td>fukushima radioactive water leak chart</td>\n",
       "      <td>antarctica chernobyl nuclear power plant cs137...</td>\n",
       "      <td>pacific ocean</td>\n",
       "      <td>asp article fukushima radiation</td>\n",
       "      <td>snopes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>photographs show toys christmas drives needy e...</td>\n",
       "      <td>false</td>\n",
       "      <td>inconnue</td>\n",
       "      <td>walmart returns full donated toys</td>\n",
       "      <td>asheville north carolina facebook toys tots wl...</td>\n",
       "      <td>walmart</td>\n",
       "      <td>asp article</td>\n",
       "      <td>snopes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>providence port 200 miles closer europe easter...</td>\n",
       "      <td>false</td>\n",
       "      <td>james bennett</td>\n",
       "      <td>incoming economic development director says pr...</td>\n",
       "      <td>angel taveras bureau transportation statistics...</td>\n",
       "      <td>inconnue</td>\n",
       "      <td>economy infrastructure trade transportation</td>\n",
       "      <td>politifact</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text RatingName  \\\n",
       "0  says 74 percent smallbusiness people believe o...      false   \n",
       "1  giant asteroid expected hit earth july two tho...      false   \n",
       "2  image shows radioactive seepage spreading acro...      false   \n",
       "3  photographs show toys christmas drives needy e...      false   \n",
       "4  providence port 200 miles closer europe easter...      false   \n",
       "\n",
       "          Author                                           Headline  \\\n",
       "0    larry elder                          claim nt pass examination   \n",
       "1       inconnue  scientists say giant asteroid could hit earth ...   \n",
       "2       inconnue             fukushima radioactive water leak chart   \n",
       "3       inconnue                  walmart returns full donated toys   \n",
       "4  james bennett  incoming economic development director says pr...   \n",
       "\n",
       "                                  NamedEntitiesClaim NamedEntitiesArticle  \\\n",
       "0  cnn lemon gallup poll larry elder marco rubio ...                  bad   \n",
       "1  asteroid columbia university facebook asteroid...             asteroid   \n",
       "2  antarctica chernobyl nuclear power plant cs137...        pacific ocean   \n",
       "3  asheville north carolina facebook toys tots wl...              walmart   \n",
       "4  angel taveras bureau transportation statistics...             inconnue   \n",
       "\n",
       "                                      Keywords      Source  \n",
       "0                                  health care  politifact  \n",
       "1                           asteroid clickbait      snopes  \n",
       "2              asp article fukushima radiation      snopes  \n",
       "3                                  asp article      snopes  \n",
       "4  economy infrastructure trade transportation  politifact  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>RatingName</th>\n",
       "      <th>Author</th>\n",
       "      <th>Headline</th>\n",
       "      <th>NamedEntitiesClaim</th>\n",
       "      <th>NamedEntitiesArticle</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>260</td>\n",
       "      <td>260</td>\n",
       "      <td>260</td>\n",
       "      <td>260</td>\n",
       "      <td>260</td>\n",
       "      <td>260</td>\n",
       "      <td>260</td>\n",
       "      <td>260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>unique</td>\n",
       "      <td>260</td>\n",
       "      <td>2</td>\n",
       "      <td>108</td>\n",
       "      <td>260</td>\n",
       "      <td>260</td>\n",
       "      <td>152</td>\n",
       "      <td>192</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>top</td>\n",
       "      <td>striped mittenfish change sex turning entire b...</td>\n",
       "      <td>false</td>\n",
       "      <td>inconnue</td>\n",
       "      <td>amc walking dead agrees bring beth greene back...</td>\n",
       "      <td>two thousand and nine college basketball invit...</td>\n",
       "      <td>inconnue</td>\n",
       "      <td>inconnue</td>\n",
       "      <td>politifact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>freq</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>134</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>18</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Text RatingName  \\\n",
       "count                                                 260        260   \n",
       "unique                                                260          2   \n",
       "top     striped mittenfish change sex turning entire b...      false   \n",
       "freq                                                    1        130   \n",
       "\n",
       "          Author                                           Headline  \\\n",
       "count        260                                                260   \n",
       "unique       108                                                260   \n",
       "top     inconnue  amc walking dead agrees bring beth greene back...   \n",
       "freq         134                                                  1   \n",
       "\n",
       "                                       NamedEntitiesClaim  \\\n",
       "count                                                 260   \n",
       "unique                                                260   \n",
       "top     two thousand and nine college basketball invit...   \n",
       "freq                                                    1   \n",
       "\n",
       "       NamedEntitiesArticle  Keywords      Source  \n",
       "count                   260       260         260  \n",
       "unique                  152       192           5  \n",
       "top                inconnue  inconnue  politifact  \n",
       "freq                     99        18         124  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfCleanDownsample = sampling(dfClean, sample = 'down')\n",
    "display(dfCleanDownsample.head())\n",
    "display(dfCleanDownsample.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we have df, dfClean, dfCleanUpsample and dfCleaneDownsample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" align=\"center\">\n",
    "    <h1>\n",
    "        Encodage\n",
    "    </h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "classLabelEncoder = LabelEncoder()\n",
    "\n",
    "tfidfVectorizer1 = TfidfVectorizer()\n",
    "tfidfVectorizer2 = TfidfVectorizer(ngram_range=(1, 2))\n",
    "\n",
    "tfidfTransformer1 = TfidfTransformer()\n",
    "tfidfTransformer2 = TfidfTransformer(use_idf = False)\n",
    "\n",
    "countVectorizer = CountVectorizer()\n",
    "\n",
    "standardScaler = StandardScaler()\n",
    "minMaxScaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the dataframe & make copies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# df\n",
    "dfHeadlineText = df[\"Headline\"] + \" \" + df[\"Text\"]\n",
    "dfRatingName = df['RatingName']\n",
    "dfAuthor = df['Author']\n",
    "dfNamedEntitiesClaim = df['NamedEntitiesClaim']\n",
    "dfNamedEntitiesArticle = df['NamedEntitiesArticle']\n",
    "dfKeywords = df['Keywords']\n",
    "dfSource = df['Source']\n",
    "\n",
    "# dfClean\n",
    "dfCleanHeadlineText = dfClean[\"Headline\"] + \" \" + dfClean[\"Text\"]\n",
    "dfCleanRatingName = dfClean['RatingName']\n",
    "dfCleanAuthor = dfClean['Author']\n",
    "dfCleanNamedEntitiesClaim = dfClean['NamedEntitiesClaim']\n",
    "dfCleanNamedEntitiesArticle = dfClean['NamedEntitiesArticle']\n",
    "dfCleanKeywords = dfClean['Keywords']\n",
    "dfCleanSource = dfClean['Source']\n",
    "\n",
    "# dfCleanUpsample\n",
    "dfCleanUpsampleHeadlineText = dfCleanUpsample[\"Headline\"] + \" \" + dfCleanUpsample[\"Text\"]\n",
    "dfCleanUpsampleRatingName = dfCleanUpsample['RatingName']\n",
    "dfCleanUpsampleAuthor = dfCleanUpsample['Author']\n",
    "dfCleanUpsampleNamedEntitiesClaim = dfCleanUpsample['NamedEntitiesClaim']\n",
    "dfCleanUpsampleNamedEntitiesArticle = dfCleanUpsample['NamedEntitiesArticle']\n",
    "dfCleanUpsampleKeywords = dfCleanUpsample['Keywords']\n",
    "dfCleanUpsampleSource = dfCleanUpsample['Source']\n",
    "\n",
    "# dfCleanDownsample\n",
    "dfCleanDownsampleHeadlineText = dfCleanDownsample[\"Headline\"] + \" \" + dfCleanDownsample[\"Text\"]\n",
    "dfCleanDownsampleRatingName = dfCleanDownsample['RatingName']\n",
    "dfCleanDownsampleAuthor = dfCleanDownsample['Author']\n",
    "dfCleanDownsampleNamedEntitiesClaim = dfCleanDownsample['NamedEntitiesClaim']\n",
    "dfCleanDownsampleNamedEntitiesArticle = dfCleanDownsample['NamedEntitiesArticle']\n",
    "dfCleanDownsampleKeywords = dfCleanDownsample['Keywords']\n",
    "dfCleanDownsampleSource = dfCleanDownsample['Source']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "    <h2>\n",
    "        TF 1\n",
    "    </h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a copy of every column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfHeadlineText1 = dfHeadlineText.copy()\n",
    "dfAuthor1 = dfAuthor.copy()\n",
    "dfNamedEntitiesClaim1 = dfNamedEntitiesClaim.copy()\n",
    "dfNamedEntitiesArticle1 = dfNamedEntitiesArticle.copy()\n",
    "dfKeywords1 = dfKeywords.copy()\n",
    "dfSource1 = dfSource.copy()\n",
    "dfRatingName1 = dfRatingName.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HeadlineText</th>\n",
       "      <th>Author</th>\n",
       "      <th>NamedEntitiesClaim</th>\n",
       "      <th>NamedEntitiesArticle</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Source</th>\n",
       "      <th>RatingName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.238703</td>\n",
       "      <td>-0.049871</td>\n",
       "      <td>1.018647</td>\n",
       "      <td>1.343932</td>\n",
       "      <td>-1.392961</td>\n",
       "      <td>0.718769</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.280394</td>\n",
       "      <td>-2.217558</td>\n",
       "      <td>1.366477</td>\n",
       "      <td>-0.328660</td>\n",
       "      <td>-0.259501</td>\n",
       "      <td>-0.799669</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.734703</td>\n",
       "      <td>-0.049871</td>\n",
       "      <td>1.508449</td>\n",
       "      <td>0.851993</td>\n",
       "      <td>-1.152226</td>\n",
       "      <td>0.718769</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.102929</td>\n",
       "      <td>2.544784</td>\n",
       "      <td>0.791492</td>\n",
       "      <td>0.894159</td>\n",
       "      <td>-1.092043</td>\n",
       "      <td>-0.799669</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-1.622026</td>\n",
       "      <td>-2.151870</td>\n",
       "      <td>-0.763098</td>\n",
       "      <td>-0.117829</td>\n",
       "      <td>-1.112104</td>\n",
       "      <td>-0.799669</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>483</td>\n",
       "      <td>-0.330084</td>\n",
       "      <td>-1.790589</td>\n",
       "      <td>-0.202310</td>\n",
       "      <td>-1.200094</td>\n",
       "      <td>-0.259501</td>\n",
       "      <td>-0.799669</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>484</td>\n",
       "      <td>-1.501350</td>\n",
       "      <td>-1.954808</td>\n",
       "      <td>0.060338</td>\n",
       "      <td>-0.708156</td>\n",
       "      <td>-0.460114</td>\n",
       "      <td>-0.799669</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>485</td>\n",
       "      <td>-0.649520</td>\n",
       "      <td>-1.593527</td>\n",
       "      <td>0.464957</td>\n",
       "      <td>-0.117829</td>\n",
       "      <td>-0.379869</td>\n",
       "      <td>-0.799669</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>486</td>\n",
       "      <td>1.508449</td>\n",
       "      <td>-0.049871</td>\n",
       "      <td>-1.316787</td>\n",
       "      <td>0.177334</td>\n",
       "      <td>1.495857</td>\n",
       "      <td>0.718769</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>487</td>\n",
       "      <td>-0.571436</td>\n",
       "      <td>-0.049871</td>\n",
       "      <td>-0.819886</td>\n",
       "      <td>1.498541</td>\n",
       "      <td>1.335367</td>\n",
       "      <td>0.718769</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>488 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     HeadlineText    Author  NamedEntitiesClaim  NamedEntitiesArticle  \\\n",
       "0        1.238703 -0.049871            1.018647              1.343932   \n",
       "1        0.280394 -2.217558            1.366477             -0.328660   \n",
       "2        0.734703 -0.049871            1.508449              0.851993   \n",
       "3        0.102929  2.544784            0.791492              0.894159   \n",
       "4       -1.622026 -2.151870           -0.763098             -0.117829   \n",
       "..            ...       ...                 ...                   ...   \n",
       "483     -0.330084 -1.790589           -0.202310             -1.200094   \n",
       "484     -1.501350 -1.954808            0.060338             -0.708156   \n",
       "485     -0.649520 -1.593527            0.464957             -0.117829   \n",
       "486      1.508449 -0.049871           -1.316787              0.177334   \n",
       "487     -0.571436 -0.049871           -0.819886              1.498541   \n",
       "\n",
       "     Keywords    Source  RatingName  \n",
       "0   -1.392961  0.718769           0  \n",
       "1   -0.259501 -0.799669           0  \n",
       "2   -1.152226  0.718769           0  \n",
       "3   -1.092043 -0.799669           1  \n",
       "4   -1.112104 -0.799669           0  \n",
       "..        ...       ...         ...  \n",
       "483 -0.259501 -0.799669           0  \n",
       "484 -0.460114 -0.799669           0  \n",
       "485 -0.379869 -0.799669           1  \n",
       "486  1.495857  0.718769           0  \n",
       "487  1.335367  0.718769           1  \n",
       "\n",
       "[488 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfHeadlineText1 = pd.DataFrame(classLabelEncoder.fit_transform(dfHeadlineText1), \n",
    "                               columns = ['HeadlineText'])\n",
    "dfHeadlineText1 = pd.DataFrame(standardScaler.fit_transform(dfHeadlineText1), \n",
    "                               columns = ['HeadlineText'])\n",
    "\n",
    "dfAuthor1 = pd.DataFrame(classLabelEncoder.fit_transform(dfAuthor1), \n",
    "                         columns = ['Author'])\n",
    "dfAuthor1 = pd.DataFrame(standardScaler.fit_transform(dfAuthor1), \n",
    "                         columns = ['Author'])\n",
    "\n",
    "dfNamedEntitiesClaim1 = pd.DataFrame(classLabelEncoder.fit_transform(dfNamedEntitiesClaim1), \n",
    "                                     columns = ['NamedEntitiesClaim'])\n",
    "dfNamedEntitiesClaim1 = pd.DataFrame(standardScaler.fit_transform(dfNamedEntitiesClaim1), \n",
    "                                     columns = ['NamedEntitiesClaim'])\n",
    "\n",
    "dfNamedEntitiesArticle1 = pd.DataFrame(classLabelEncoder.fit_transform(dfNamedEntitiesArticle1), \n",
    "                                       columns = ['NamedEntitiesArticle'])\n",
    "dfNamedEntitiesArticle1 = pd.DataFrame(standardScaler.fit_transform(dfNamedEntitiesArticle1), \n",
    "                                       columns = ['NamedEntitiesArticle'])\n",
    "\n",
    "dfKeywords1 = pd.DataFrame(classLabelEncoder.fit_transform(dfKeywords1), \n",
    "                           columns = ['Keywords'])\n",
    "dfKeywords1 = pd.DataFrame(standardScaler.fit_transform(dfKeywords1), \n",
    "                           columns = ['Keywords'])\n",
    "\n",
    "dfSource1 = pd.DataFrame(classLabelEncoder.fit_transform(dfSource1), \n",
    "                         columns = ['Source'])\n",
    "dfSource1 = pd.DataFrame(standardScaler.fit_transform(dfSource1), \n",
    "                         columns = ['Source'])\n",
    "\n",
    "dfRatingName1 = pd.DataFrame(classLabelEncoder.fit_transform(dfRatingName1), \n",
    "                             columns = ['RatingName'])\n",
    "\n",
    "df1 = pd.concat([dfHeadlineText1, dfAuthor1, dfNamedEntitiesClaim1, dfNamedEntitiesArticle1, \n",
    "                 dfKeywords1, dfSource1, dfRatingName1], axis = 1)\n",
    "\n",
    "display(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the transformed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv('attemps/tf1.csv', sep = ';', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "    <h2>\n",
    "        TF cleaned 1\n",
    "    </h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a copy of every column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCleanHeadlineText1 = dfCleanHeadlineText.copy()\n",
    "dfCleanAuthor1 = dfCleanAuthor.copy()\n",
    "dfCleanNamedEntitiesClaim1 = dfCleanNamedEntitiesClaim.copy()\n",
    "dfCleanNamedEntitiesArticle1 = dfCleanNamedEntitiesArticle.copy()\n",
    "dfCleanKeywords1 = dfCleanKeywords.copy()\n",
    "dfCleanSource1 = dfCleanSource.copy()\n",
    "dfCleanRatingName1 = dfCleanRatingName.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HeadlineText</th>\n",
       "      <th>Author</th>\n",
       "      <th>NamedEntitiesClaim</th>\n",
       "      <th>NamedEntitiesArticle</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Source</th>\n",
       "      <th>RatingName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.316787</td>\n",
       "      <td>-0.051841</td>\n",
       "      <td>0.578535</td>\n",
       "      <td>1.635848</td>\n",
       "      <td>-1.148052</td>\n",
       "      <td>0.718769</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.039042</td>\n",
       "      <td>-2.192984</td>\n",
       "      <td>0.961858</td>\n",
       "      <td>-0.256948</td>\n",
       "      <td>0.429747</td>\n",
       "      <td>-0.799669</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.521746</td>\n",
       "      <td>-0.051841</td>\n",
       "      <td>1.103830</td>\n",
       "      <td>1.070834</td>\n",
       "      <td>-1.036019</td>\n",
       "      <td>0.718769</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.649520</td>\n",
       "      <td>2.550472</td>\n",
       "      <td>0.301690</td>\n",
       "      <td>1.141461</td>\n",
       "      <td>-1.652201</td>\n",
       "      <td>-0.799669</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-1.614928</td>\n",
       "      <td>-2.127103</td>\n",
       "      <td>-1.252900</td>\n",
       "      <td>-0.002692</td>\n",
       "      <td>-1.670874</td>\n",
       "      <td>-0.799669</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>483</td>\n",
       "      <td>-0.614027</td>\n",
       "      <td>-1.764756</td>\n",
       "      <td>-0.663718</td>\n",
       "      <td>-0.836087</td>\n",
       "      <td>0.429747</td>\n",
       "      <td>-0.799669</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>484</td>\n",
       "      <td>-1.529745</td>\n",
       "      <td>-1.929459</td>\n",
       "      <td>-0.401070</td>\n",
       "      <td>-0.680708</td>\n",
       "      <td>0.037631</td>\n",
       "      <td>-0.799669</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>485</td>\n",
       "      <td>0.564337</td>\n",
       "      <td>-1.567112</td>\n",
       "      <td>0.024845</td>\n",
       "      <td>-0.002692</td>\n",
       "      <td>0.289706</td>\n",
       "      <td>-0.799669</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>486</td>\n",
       "      <td>-0.145521</td>\n",
       "      <td>-0.051841</td>\n",
       "      <td>1.558139</td>\n",
       "      <td>0.279815</td>\n",
       "      <td>0.485764</td>\n",
       "      <td>0.718769</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>487</td>\n",
       "      <td>1.579435</td>\n",
       "      <td>-0.051841</td>\n",
       "      <td>-1.309689</td>\n",
       "      <td>1.791227</td>\n",
       "      <td>0.168337</td>\n",
       "      <td>0.718769</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>488 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     HeadlineText    Author  NamedEntitiesClaim  NamedEntitiesArticle  \\\n",
       "0        1.316787 -0.051841            0.578535              1.635848   \n",
       "1        0.039042 -2.192984            0.961858             -0.256948   \n",
       "2        0.521746 -0.051841            1.103830              1.070834   \n",
       "3        0.649520  2.550472            0.301690              1.141461   \n",
       "4       -1.614928 -2.127103           -1.252900             -0.002692   \n",
       "..            ...       ...                 ...                   ...   \n",
       "483     -0.614027 -1.764756           -0.663718             -0.836087   \n",
       "484     -1.529745 -1.929459           -0.401070             -0.680708   \n",
       "485      0.564337 -1.567112            0.024845             -0.002692   \n",
       "486     -0.145521 -0.051841            1.558139              0.279815   \n",
       "487      1.579435 -0.051841           -1.309689              1.791227   \n",
       "\n",
       "     Keywords    Source  RatingName  \n",
       "0   -1.148052  0.718769           0  \n",
       "1    0.429747 -0.799669           0  \n",
       "2   -1.036019  0.718769           0  \n",
       "3   -1.652201 -0.799669           1  \n",
       "4   -1.670874 -0.799669           0  \n",
       "..        ...       ...         ...  \n",
       "483  0.429747 -0.799669           0  \n",
       "484  0.037631 -0.799669           0  \n",
       "485  0.289706 -0.799669           1  \n",
       "486  0.485764  0.718769           0  \n",
       "487  0.168337  0.718769           1  \n",
       "\n",
       "[488 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfCleanHeadlineText1 = pd.DataFrame(classLabelEncoder.fit_transform(dfCleanHeadlineText1), \n",
    "                                    columns = ['HeadlineText'])\n",
    "dfCleanHeadlineText1 = pd.DataFrame(standardScaler.fit_transform(dfCleanHeadlineText1), \n",
    "                                    columns = ['HeadlineText'])\n",
    "\n",
    "dfCleanAuthor1 = pd.DataFrame(classLabelEncoder.fit_transform(dfCleanAuthor1), \n",
    "                              columns = ['Author'])\n",
    "dfCleanAuthor1 = pd.DataFrame(standardScaler.fit_transform(dfCleanAuthor1), \n",
    "                              columns = ['Author'])\n",
    "\n",
    "dfCleanNamedEntitiesClaim1 = pd.DataFrame(classLabelEncoder.fit_transform(dfCleanNamedEntitiesClaim1), \n",
    "                                          columns = ['NamedEntitiesClaim'])\n",
    "dfCleanNamedEntitiesClaim1 = pd.DataFrame(standardScaler.fit_transform(dfCleanNamedEntitiesClaim1), \n",
    "                                          columns = ['NamedEntitiesClaim'])\n",
    "\n",
    "dfCleanNamedEntitiesArticle1 = pd.DataFrame(classLabelEncoder.fit_transform(dfCleanNamedEntitiesArticle1), \n",
    "                                            columns = ['NamedEntitiesArticle'])\n",
    "dfCleanNamedEntitiesArticle1 = pd.DataFrame(standardScaler.fit_transform(dfCleanNamedEntitiesArticle1), \n",
    "                                            columns = ['NamedEntitiesArticle'])\n",
    "\n",
    "dfCleanKeywords1 = pd.DataFrame(classLabelEncoder.fit_transform(dfCleanKeywords1), \n",
    "                                columns = ['Keywords'])\n",
    "dfCleanKeywords1 = pd.DataFrame(standardScaler.fit_transform(dfCleanKeywords1), \n",
    "                                columns = ['Keywords'])\n",
    "\n",
    "dfCleanSource1 = pd.DataFrame(classLabelEncoder.fit_transform(dfCleanSource1), \n",
    "                              columns = ['Source'])\n",
    "dfCleanSource1 = pd.DataFrame(standardScaler.fit_transform(dfCleanSource1), \n",
    "                              columns = ['Source'])\n",
    "\n",
    "dfCleanRatingName1 = pd.DataFrame(classLabelEncoder.fit_transform(dfCleanRatingName1), \n",
    "                                  columns = ['RatingName'])\n",
    "\n",
    "dfClean1 = pd.concat([dfCleanHeadlineText1, dfCleanAuthor1, dfCleanNamedEntitiesClaim1, dfCleanNamedEntitiesArticle1, \n",
    "                      dfCleanKeywords1, dfCleanSource1, dfCleanRatingName1], axis = 1)\n",
    "\n",
    "display(dfClean1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the transformed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfClean1.to_csv('attemps/tfclean1.csv', sep = ';', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "    <h2>\n",
    "        TF cleaned upsampled 1\n",
    "    </h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a copy of every column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCleanUpsampleHeadlineText1 = dfCleanUpsampleHeadlineText.copy()\n",
    "dfCleanUpsampleAuthor1 = dfCleanUpsampleAuthor.copy()\n",
    "dfCleanUpsampleNamedEntitiesClaim1 = dfCleanUpsampleNamedEntitiesClaim.copy()\n",
    "dfCleanUpsampleNamedEntitiesArticle1 = dfCleanUpsampleNamedEntitiesArticle.copy()\n",
    "dfCleanUpsampleKeywords1 = dfCleanUpsampleKeywords.copy()\n",
    "dfCleanUpsampleSource1 = dfCleanUpsampleSource.copy()\n",
    "dfCleanUpsampleRatingName1 = dfCleanUpsampleRatingName.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HeadlineText</th>\n",
       "      <th>Author</th>\n",
       "      <th>NamedEntitiesClaim</th>\n",
       "      <th>NamedEntitiesArticle</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Source</th>\n",
       "      <th>RatingName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.649966</td>\n",
       "      <td>-0.065213</td>\n",
       "      <td>0.469314</td>\n",
       "      <td>-0.020832</td>\n",
       "      <td>-1.051105</td>\n",
       "      <td>0.822997</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-1.410355</td>\n",
       "      <td>-0.065213</td>\n",
       "      <td>1.081349</td>\n",
       "      <td>2.056934</td>\n",
       "      <td>-0.779915</td>\n",
       "      <td>0.822997</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-0.548094</td>\n",
       "      <td>-0.065213</td>\n",
       "      <td>0.814934</td>\n",
       "      <td>-0.347338</td>\n",
       "      <td>0.837878</td>\n",
       "      <td>0.822997</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-1.049901</td>\n",
       "      <td>1.290993</td>\n",
       "      <td>1.174955</td>\n",
       "      <td>-0.020832</td>\n",
       "      <td>-0.050505</td>\n",
       "      <td>-0.711549</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-0.406739</td>\n",
       "      <td>-2.131812</td>\n",
       "      <td>-1.064374</td>\n",
       "      <td>-0.228608</td>\n",
       "      <td>0.931392</td>\n",
       "      <td>-0.711549</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>711</td>\n",
       "      <td>-1.678928</td>\n",
       "      <td>-0.065213</td>\n",
       "      <td>1.736587</td>\n",
       "      <td>2.131140</td>\n",
       "      <td>1.034257</td>\n",
       "      <td>2.357542</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>712</td>\n",
       "      <td>1.240039</td>\n",
       "      <td>2.614908</td>\n",
       "      <td>-0.157122</td>\n",
       "      <td>1.700745</td>\n",
       "      <td>0.847229</td>\n",
       "      <td>-0.711549</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>713</td>\n",
       "      <td>-1.572912</td>\n",
       "      <td>-0.065213</td>\n",
       "      <td>-0.553145</td>\n",
       "      <td>-0.020832</td>\n",
       "      <td>1.034257</td>\n",
       "      <td>0.822997</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>714</td>\n",
       "      <td>0.533267</td>\n",
       "      <td>-0.065213</td>\n",
       "      <td>-1.165180</td>\n",
       "      <td>-0.020832</td>\n",
       "      <td>1.034257</td>\n",
       "      <td>0.822997</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>715</td>\n",
       "      <td>0.568606</td>\n",
       "      <td>-0.065213</td>\n",
       "      <td>1.354965</td>\n",
       "      <td>-0.020832</td>\n",
       "      <td>1.539233</td>\n",
       "      <td>0.822997</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>716 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     HeadlineText    Author  NamedEntitiesClaim  NamedEntitiesArticle  \\\n",
       "0        1.649966 -0.065213            0.469314             -0.020832   \n",
       "1       -1.410355 -0.065213            1.081349              2.056934   \n",
       "2       -0.548094 -0.065213            0.814934             -0.347338   \n",
       "3       -1.049901  1.290993            1.174955             -0.020832   \n",
       "4       -0.406739 -2.131812           -1.064374             -0.228608   \n",
       "..            ...       ...                 ...                   ...   \n",
       "711     -1.678928 -0.065213            1.736587              2.131140   \n",
       "712      1.240039  2.614908           -0.157122              1.700745   \n",
       "713     -1.572912 -0.065213           -0.553145             -0.020832   \n",
       "714      0.533267 -0.065213           -1.165180             -0.020832   \n",
       "715      0.568606 -0.065213            1.354965             -0.020832   \n",
       "\n",
       "     Keywords    Source  RatingName  \n",
       "0   -1.051105  0.822997           1  \n",
       "1   -0.779915  0.822997           0  \n",
       "2    0.837878  0.822997           0  \n",
       "3   -0.050505 -0.711549           1  \n",
       "4    0.931392 -0.711549           1  \n",
       "..        ...       ...         ...  \n",
       "711  1.034257  2.357542           1  \n",
       "712  0.847229 -0.711549           0  \n",
       "713  1.034257  0.822997           1  \n",
       "714  1.034257  0.822997           0  \n",
       "715  1.539233  0.822997           1  \n",
       "\n",
       "[716 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfCleanUpsampleHeadlineText1 = pd.DataFrame(classLabelEncoder.fit_transform(dfCleanUpsampleHeadlineText1), \n",
    "                                            columns = ['HeadlineText'])\n",
    "dfCleanUpsampleHeadlineText1 = pd.DataFrame(standardScaler.fit_transform(dfCleanUpsampleHeadlineText1), \n",
    "                                            columns = ['HeadlineText'])\n",
    "\n",
    "dfCleanUpsampleAuthor1 = pd.DataFrame(classLabelEncoder.fit_transform(dfCleanUpsampleAuthor1), \n",
    "                                      columns = ['Author'])\n",
    "dfCleanUpsampleAuthor1 = pd.DataFrame(standardScaler.fit_transform(dfCleanUpsampleAuthor1), \n",
    "                                      columns = ['Author'])\n",
    "\n",
    "dfCleanUpsampleNamedEntitiesClaim1 = pd.DataFrame(classLabelEncoder.fit_transform(dfCleanUpsampleNamedEntitiesClaim1), \n",
    "                                                  columns = ['NamedEntitiesClaim'])\n",
    "dfCleanUpsampleNamedEntitiesClaim1 = pd.DataFrame(standardScaler.fit_transform(dfCleanUpsampleNamedEntitiesClaim1), \n",
    "                                                  columns = ['NamedEntitiesClaim'])\n",
    "\n",
    "dfCleanUpsampleNamedEntitiesArticle1 = pd.DataFrame(classLabelEncoder.fit_transform(dfCleanUpsampleNamedEntitiesArticle1), \n",
    "                                                    columns = ['NamedEntitiesArticle'])\n",
    "dfCleanUpsampleNamedEntitiesArticle1 = pd.DataFrame(standardScaler.fit_transform(dfCleanUpsampleNamedEntitiesArticle1), \n",
    "                                                    columns = ['NamedEntitiesArticle'])\n",
    "\n",
    "dfCleanUpsampleKeywords1 = pd.DataFrame(classLabelEncoder.fit_transform(dfCleanUpsampleKeywords1), \n",
    "                                        columns = ['Keywords'])\n",
    "dfCleanUpsampleKeywords1 = pd.DataFrame(standardScaler.fit_transform(dfCleanUpsampleKeywords1), \n",
    "                                        columns = ['Keywords'])\n",
    "\n",
    "dfCleanUpsampleSource1 = pd.DataFrame(classLabelEncoder.fit_transform(dfCleanUpsampleSource1), \n",
    "                                      columns = ['Source'])\n",
    "dfCleanUpsampleSource1 = pd.DataFrame(standardScaler.fit_transform(dfCleanUpsampleSource1), \n",
    "                                      columns = ['Source'])\n",
    "\n",
    "dfCleanUpsampleRatingName1 = pd.DataFrame(classLabelEncoder.fit_transform(dfCleanUpsampleRatingName1), \n",
    "                                          columns = ['RatingName'])\n",
    "\n",
    "dfCleanUpsample1 = pd.concat([dfCleanUpsampleHeadlineText1, dfCleanUpsampleAuthor1, dfCleanUpsampleNamedEntitiesClaim1, \n",
    "                              dfCleanUpsampleNamedEntitiesArticle1, dfCleanUpsampleKeywords1, dfCleanUpsampleSource1, \n",
    "                              dfCleanUpsampleRatingName1], axis = 1)\n",
    "\n",
    "display(dfCleanUpsample1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the transformed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCleanUpsample1.to_csv('attemps/tfcleanupsample1.csv', sep = ';', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "    <h2>\n",
    "        TF cleaned downsampled 1\n",
    "    </h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a copy of every column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCleanDownsampleHeadlineText1 = dfCleanDownsampleHeadlineText.copy()\n",
    "dfCleanDownsampleAuthor1 = dfCleanDownsampleAuthor.copy()\n",
    "dfCleanDownsampleNamedEntitiesClaim1 = dfCleanDownsampleNamedEntitiesClaim.copy()\n",
    "dfCleanDownsampleNamedEntitiesArticle1 = dfCleanDownsampleNamedEntitiesArticle.copy()\n",
    "dfCleanDownsampleKeywords1 = dfCleanDownsampleKeywords.copy()\n",
    "dfCleanDownsampleSource1 = dfCleanDownsampleSource.copy()\n",
    "dfCleanDownsampleRatingName1 = dfCleanDownsampleRatingName.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HeadlineText</th>\n",
       "      <th>Author</th>\n",
       "      <th>NamedEntitiesClaim</th>\n",
       "      <th>NamedEntitiesArticle</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Source</th>\n",
       "      <th>RatingName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-1.125841</td>\n",
       "      <td>0.519433</td>\n",
       "      <td>0.526281</td>\n",
       "      <td>-1.703285</td>\n",
       "      <td>0.893189</td>\n",
       "      <td>-0.760398</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.072547</td>\n",
       "      <td>-0.150249</td>\n",
       "      <td>-0.539604</td>\n",
       "      <td>-1.731990</td>\n",
       "      <td>-0.919887</td>\n",
       "      <td>0.784160</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-0.552928</td>\n",
       "      <td>-0.150249</td>\n",
       "      <td>-0.752781</td>\n",
       "      <td>1.052354</td>\n",
       "      <td>-1.265234</td>\n",
       "      <td>0.784160</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.605490</td>\n",
       "      <td>-0.150249</td>\n",
       "      <td>-0.632869</td>\n",
       "      <td>1.970900</td>\n",
       "      <td>-1.386106</td>\n",
       "      <td>0.784160</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-0.166545</td>\n",
       "      <td>-0.060958</td>\n",
       "      <td>-0.792752</td>\n",
       "      <td>-0.038420</td>\n",
       "      <td>0.409702</td>\n",
       "      <td>-0.760398</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>255</td>\n",
       "      <td>1.019253</td>\n",
       "      <td>1.858797</td>\n",
       "      <td>0.699487</td>\n",
       "      <td>1.425513</td>\n",
       "      <td>-0.678143</td>\n",
       "      <td>-0.760398</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>256</td>\n",
       "      <td>-0.393045</td>\n",
       "      <td>-1.980714</td>\n",
       "      <td>-0.965959</td>\n",
       "      <td>-0.268057</td>\n",
       "      <td>0.893189</td>\n",
       "      <td>-0.760398</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>257</td>\n",
       "      <td>-0.632869</td>\n",
       "      <td>-0.864577</td>\n",
       "      <td>-0.246486</td>\n",
       "      <td>0.736603</td>\n",
       "      <td>0.116156</td>\n",
       "      <td>-0.760398</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>258</td>\n",
       "      <td>0.566252</td>\n",
       "      <td>-1.534259</td>\n",
       "      <td>0.099927</td>\n",
       "      <td>-0.038420</td>\n",
       "      <td>0.323365</td>\n",
       "      <td>-0.760398</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>259</td>\n",
       "      <td>1.578843</td>\n",
       "      <td>-0.150249</td>\n",
       "      <td>-1.219106</td>\n",
       "      <td>1.798673</td>\n",
       "      <td>0.202493</td>\n",
       "      <td>0.784160</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>260 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     HeadlineText    Author  NamedEntitiesClaim  NamedEntitiesArticle  \\\n",
       "0       -1.125841  0.519433            0.526281             -1.703285   \n",
       "1        1.072547 -0.150249           -0.539604             -1.731990   \n",
       "2       -0.552928 -0.150249           -0.752781              1.052354   \n",
       "3        1.605490 -0.150249           -0.632869              1.970900   \n",
       "4       -0.166545 -0.060958           -0.792752             -0.038420   \n",
       "..            ...       ...                 ...                   ...   \n",
       "255      1.019253  1.858797            0.699487              1.425513   \n",
       "256     -0.393045 -1.980714           -0.965959             -0.268057   \n",
       "257     -0.632869 -0.864577           -0.246486              0.736603   \n",
       "258      0.566252 -1.534259            0.099927             -0.038420   \n",
       "259      1.578843 -0.150249           -1.219106              1.798673   \n",
       "\n",
       "     Keywords    Source  RatingName  \n",
       "0    0.893189 -0.760398           0  \n",
       "1   -0.919887  0.784160           0  \n",
       "2   -1.265234  0.784160           0  \n",
       "3   -1.386106  0.784160           0  \n",
       "4    0.409702 -0.760398           0  \n",
       "..        ...       ...         ...  \n",
       "255 -0.678143 -0.760398           1  \n",
       "256  0.893189 -0.760398           1  \n",
       "257  0.116156 -0.760398           1  \n",
       "258  0.323365 -0.760398           1  \n",
       "259  0.202493  0.784160           1  \n",
       "\n",
       "[260 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfCleanDownsampleHeadlineText1 = pd.DataFrame(classLabelEncoder.fit_transform(dfCleanDownsampleHeadlineText1), \n",
    "                                              columns = ['HeadlineText'])\n",
    "dfCleanDownsampleHeadlineText1 = pd.DataFrame(standardScaler.fit_transform(dfCleanDownsampleHeadlineText1), \n",
    "                                              columns = ['HeadlineText'])\n",
    "\n",
    "dfCleanDownsampleAuthor1 = pd.DataFrame(classLabelEncoder.fit_transform(dfCleanDownsampleAuthor1), \n",
    "                                        columns = ['Author'])\n",
    "dfCleanDownsampleAuthor1 = pd.DataFrame(standardScaler.fit_transform(dfCleanDownsampleAuthor1), \n",
    "                                        columns = ['Author'])\n",
    "\n",
    "dfCleanDownsampleNamedEntitiesClaim1 = pd.DataFrame(classLabelEncoder.fit_transform(dfCleanDownsampleNamedEntitiesClaim1), \n",
    "                                                    columns = ['NamedEntitiesClaim'])\n",
    "dfCleanDownsampleNamedEntitiesClaim1 = pd.DataFrame(standardScaler.fit_transform(dfCleanDownsampleNamedEntitiesClaim1), \n",
    "                                                    columns = ['NamedEntitiesClaim'])\n",
    "\n",
    "dfCleanDownsampleNamedEntitiesArticle1 = pd.DataFrame(classLabelEncoder.fit_transform(dfCleanDownsampleNamedEntitiesArticle1), \n",
    "                                                      columns = ['NamedEntitiesArticle'])\n",
    "dfCleanDownsampleNamedEntitiesArticle1 = pd.DataFrame(standardScaler.fit_transform(dfCleanDownsampleNamedEntitiesArticle1), \n",
    "                                                      columns = ['NamedEntitiesArticle'])\n",
    "\n",
    "dfCleanDownsampleKeywords1 = pd.DataFrame(classLabelEncoder.fit_transform(dfCleanDownsampleKeywords1), \n",
    "                                          columns = ['Keywords'])\n",
    "dfCleanDownsampleKeywords1 = pd.DataFrame(standardScaler.fit_transform(dfCleanDownsampleKeywords1), \n",
    "                                          columns = ['Keywords'])\n",
    "\n",
    "dfCleanDownsampleSource1 = pd.DataFrame(classLabelEncoder.fit_transform(dfCleanDownsampleSource1), \n",
    "                                        columns = ['Source'])\n",
    "dfCleanDownsampleSource1 = pd.DataFrame(standardScaler.fit_transform(dfCleanDownsampleSource1), \n",
    "                                        columns = ['Source'])\n",
    "\n",
    "dfCleanDownsampleRatingName1 = pd.DataFrame(classLabelEncoder.fit_transform(dfCleanDownsampleRatingName1), \n",
    "                                            columns = ['RatingName'])\n",
    "\n",
    "dfCleanDownsample1 = pd.concat([dfCleanDownsampleHeadlineText1, dfCleanDownsampleAuthor1, \n",
    "                                dfCleanDownsampleNamedEntitiesClaim1, dfCleanDownsampleNamedEntitiesArticle1, \n",
    "                                dfCleanDownsampleKeywords1, dfCleanDownsampleSource1, dfCleanDownsampleRatingName1], \n",
    "                               axis = 1)\n",
    "\n",
    "display(dfCleanDownsample1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the transformed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCleanDownsample1.to_csv('attemps/tfcleandownsample1.csv', sep = ';', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "    <h2>\n",
    "        TF2\n",
    "    </h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a copy of every column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfHeadlineText2 = dfHeadlineText.copy()\n",
    "dfAuthor2 = dfAuthor.copy()\n",
    "dfNamedEntitiesClaim2 = dfNamedEntitiesClaim.copy()\n",
    "dfNamedEntitiesArticle2 = dfNamedEntitiesArticle.copy()\n",
    "dfKeywords2 = dfKeywords.copy()\n",
    "dfSource2 = dfSource.copy()\n",
    "dfRatingName2 = dfRatingName.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>100k</th>\n",
       "      <th>101st</th>\n",
       "      <th>102</th>\n",
       "      <th>106</th>\n",
       "      <th>11</th>\n",
       "      <th>120</th>\n",
       "      <th>13</th>\n",
       "      <th>...</th>\n",
       "      <th>zimmerman</th>\n",
       "      <th>zipper</th>\n",
       "      <th>zippered</th>\n",
       "      <th>zuma</th>\n",
       "      <th>Source_africacheck</th>\n",
       "      <th>Source_factscan</th>\n",
       "      <th>Source_politifact</th>\n",
       "      <th>Source_snopes</th>\n",
       "      <th>Source_truthorfiction</th>\n",
       "      <th>RatingName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-0.200002</td>\n",
       "      <td>-0.062592</td>\n",
       "      <td>-0.087289</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.075263</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.200002</td>\n",
       "      <td>-0.062592</td>\n",
       "      <td>-0.087289</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.075263</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-0.200002</td>\n",
       "      <td>-0.062592</td>\n",
       "      <td>-0.087289</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.075263</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-0.200002</td>\n",
       "      <td>-0.062592</td>\n",
       "      <td>-0.087289</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.075263</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-0.200002</td>\n",
       "      <td>-0.062592</td>\n",
       "      <td>-0.087289</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.075263</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>483</td>\n",
       "      <td>-0.200002</td>\n",
       "      <td>-0.062592</td>\n",
       "      <td>-0.087289</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.075263</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>484</td>\n",
       "      <td>-0.200002</td>\n",
       "      <td>-0.062592</td>\n",
       "      <td>-0.087289</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.075263</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>485</td>\n",
       "      <td>-0.200002</td>\n",
       "      <td>-0.062592</td>\n",
       "      <td>-0.087289</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.075263</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>486</td>\n",
       "      <td>-0.200002</td>\n",
       "      <td>-0.062592</td>\n",
       "      <td>-0.087289</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.075263</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>487</td>\n",
       "      <td>-0.200002</td>\n",
       "      <td>-0.062592</td>\n",
       "      <td>-0.087289</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.075263</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>488 rows × 3527 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          000        10       100      100k     101st       102       106  \\\n",
       "0   -0.200002 -0.062592 -0.087289 -0.045314 -0.045314 -0.045314 -0.045314   \n",
       "1   -0.200002 -0.062592 -0.087289 -0.045314 -0.045314 -0.045314 -0.045314   \n",
       "2   -0.200002 -0.062592 -0.087289 -0.045314 -0.045314 -0.045314 -0.045314   \n",
       "3   -0.200002 -0.062592 -0.087289 -0.045314 -0.045314 -0.045314 -0.045314   \n",
       "4   -0.200002 -0.062592 -0.087289 -0.045314 -0.045314 -0.045314 -0.045314   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "483 -0.200002 -0.062592 -0.087289 -0.045314 -0.045314 -0.045314 -0.045314   \n",
       "484 -0.200002 -0.062592 -0.087289 -0.045314 -0.045314 -0.045314 -0.045314   \n",
       "485 -0.200002 -0.062592 -0.087289 -0.045314 -0.045314 -0.045314 -0.045314   \n",
       "486 -0.200002 -0.062592 -0.087289 -0.045314 -0.045314 -0.045314 -0.045314   \n",
       "487 -0.200002 -0.062592 -0.087289 -0.045314 -0.045314 -0.045314 -0.045314   \n",
       "\n",
       "           11       120        13  ...  zimmerman    zipper  zippered  \\\n",
       "0   -0.045314 -0.045314 -0.075263  ...  -0.045314 -0.045314 -0.045314   \n",
       "1   -0.045314 -0.045314 -0.075263  ...  -0.045314 -0.045314 -0.045314   \n",
       "2   -0.045314 -0.045314 -0.075263  ...  -0.045314 -0.045314 -0.045314   \n",
       "3   -0.045314 -0.045314 -0.075263  ...  -0.045314 -0.045314 -0.045314   \n",
       "4   -0.045314 -0.045314 -0.075263  ...  -0.045314 -0.045314 -0.045314   \n",
       "..        ...       ...       ...  ...        ...       ...       ...   \n",
       "483 -0.045314 -0.045314 -0.075263  ...  -0.045314 -0.045314 -0.045314   \n",
       "484 -0.045314 -0.045314 -0.075263  ...  -0.045314 -0.045314 -0.045314   \n",
       "485 -0.045314 -0.045314 -0.075263  ...  -0.045314 -0.045314 -0.045314   \n",
       "486 -0.045314 -0.045314 -0.075263  ...  -0.045314 -0.045314 -0.045314   \n",
       "487 -0.045314 -0.045314 -0.075263  ...  -0.045314 -0.045314 -0.045314   \n",
       "\n",
       "         zuma  Source_africacheck  Source_factscan  Source_politifact  \\\n",
       "0   -0.045314                   0                0                  0   \n",
       "1   -0.045314                   0                0                  1   \n",
       "2   -0.045314                   0                0                  0   \n",
       "3   -0.045314                   0                0                  1   \n",
       "4   -0.045314                   0                0                  1   \n",
       "..        ...                 ...              ...                ...   \n",
       "483 -0.045314                   0                0                  1   \n",
       "484 -0.045314                   0                0                  1   \n",
       "485 -0.045314                   0                0                  1   \n",
       "486 -0.045314                   0                0                  0   \n",
       "487 -0.045314                   0                0                  0   \n",
       "\n",
       "     Source_snopes  Source_truthorfiction  RatingName  \n",
       "0                1                      0           0  \n",
       "1                0                      0           0  \n",
       "2                1                      0           0  \n",
       "3                0                      0           1  \n",
       "4                0                      0           0  \n",
       "..             ...                    ...         ...  \n",
       "483              0                      0           0  \n",
       "484              0                      0           0  \n",
       "485              0                      0           1  \n",
       "486              1                      0           0  \n",
       "487              1                      0           1  \n",
       "\n",
       "[488 rows x 3527 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfHeadlineText2 = pd.DataFrame(tfidfVectorizer1.fit_transform(dfHeadlineText2).toarray(), \n",
    "                               columns = tfidfVectorizer1.get_feature_names())\n",
    "dfHeadlineText2 = pd.DataFrame(standardScaler.fit_transform(dfHeadlineText2), \n",
    "                               columns = tfidfVectorizer1.get_feature_names())\n",
    "\n",
    "dfSource2 = pd.get_dummies(dfSource2, columns = ['Source'], prefix = 'Source').reset_index(drop = True)\n",
    "\n",
    "dfRatingName2 = pd.DataFrame(classLabelEncoder.fit_transform(dfRatingName2), columns = ['RatingName'])\n",
    "\n",
    "df2 = pd.concat([dfHeadlineText2, dfSource2, dfRatingName2], axis = 1)\n",
    "\n",
    "display(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the transformed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv('attemps/tf2.csv', sep = ';', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "    <h2>\n",
    "        TF cleaned 2\n",
    "    </h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a copy of every column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCleanHeadlineText2 = dfCleanHeadlineText.copy()\n",
    "dfCleanAuthor2 = dfCleanAuthor.copy()\n",
    "dfCleanNamedEntitiesClaim2 = dfCleanNamedEntitiesClaim.copy()\n",
    "dfCleanNamedEntitiesArticle2 = dfCleanNamedEntitiesArticle.copy()\n",
    "dfCleanKeywords2 = dfCleanKeywords.copy()\n",
    "dfCleanSource2 = dfCleanSource.copy()\n",
    "dfCleanRatingName2 = dfCleanRatingName.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>05</th>\n",
       "      <th>1000</th>\n",
       "      <th>10000</th>\n",
       "      <th>100000</th>\n",
       "      <th>100k</th>\n",
       "      <th>101st</th>\n",
       "      <th>102000</th>\n",
       "      <th>106000</th>\n",
       "      <th>1270</th>\n",
       "      <th>150000</th>\n",
       "      <th>...</th>\n",
       "      <th>zimmerman</th>\n",
       "      <th>zipper</th>\n",
       "      <th>zippered</th>\n",
       "      <th>zuma</th>\n",
       "      <th>Source_africacheck</th>\n",
       "      <th>Source_factscan</th>\n",
       "      <th>Source_politifact</th>\n",
       "      <th>Source_snopes</th>\n",
       "      <th>Source_truthorfiction</th>\n",
       "      <th>RatingName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>22.068076</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>483</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>484</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>485</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>486</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>487</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>-0.045314</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>488 rows × 3423 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           05      1000     10000    100000      100k     101st    102000  \\\n",
       "0   -0.045314 -0.045314 -0.045314 -0.045314 -0.045314 -0.045314 -0.045314   \n",
       "1   -0.045314 -0.045314 -0.045314 -0.045314 -0.045314 -0.045314 -0.045314   \n",
       "2   -0.045314 -0.045314 -0.045314 -0.045314 -0.045314 -0.045314 -0.045314   \n",
       "3   -0.045314 -0.045314 -0.045314 -0.045314 -0.045314 -0.045314 -0.045314   \n",
       "4   -0.045314 -0.045314 -0.045314 -0.045314 -0.045314 -0.045314 -0.045314   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "483 -0.045314 -0.045314 -0.045314 -0.045314 -0.045314 -0.045314 -0.045314   \n",
       "484 -0.045314 -0.045314 -0.045314 -0.045314 -0.045314 -0.045314 -0.045314   \n",
       "485 -0.045314 -0.045314 -0.045314 -0.045314 -0.045314 -0.045314 -0.045314   \n",
       "486 -0.045314 -0.045314 -0.045314 -0.045314 -0.045314 -0.045314 -0.045314   \n",
       "487 -0.045314 -0.045314 -0.045314 -0.045314 -0.045314 -0.045314 -0.045314   \n",
       "\n",
       "       106000       1270    150000  ...  zimmerman    zipper  zippered  \\\n",
       "0   -0.045314  -0.045314 -0.045314  ...  -0.045314 -0.045314 -0.045314   \n",
       "1   -0.045314  -0.045314 -0.045314  ...  -0.045314 -0.045314 -0.045314   \n",
       "2   -0.045314  -0.045314 -0.045314  ...  -0.045314 -0.045314 -0.045314   \n",
       "3   -0.045314  -0.045314 -0.045314  ...  -0.045314 -0.045314 -0.045314   \n",
       "4   -0.045314  22.068076 -0.045314  ...  -0.045314 -0.045314 -0.045314   \n",
       "..        ...        ...       ...  ...        ...       ...       ...   \n",
       "483 -0.045314  -0.045314 -0.045314  ...  -0.045314 -0.045314 -0.045314   \n",
       "484 -0.045314  -0.045314 -0.045314  ...  -0.045314 -0.045314 -0.045314   \n",
       "485 -0.045314  -0.045314 -0.045314  ...  -0.045314 -0.045314 -0.045314   \n",
       "486 -0.045314  -0.045314 -0.045314  ...  -0.045314 -0.045314 -0.045314   \n",
       "487 -0.045314  -0.045314 -0.045314  ...  -0.045314 -0.045314 -0.045314   \n",
       "\n",
       "         zuma  Source_africacheck  Source_factscan  Source_politifact  \\\n",
       "0   -0.045314                   0                0                  0   \n",
       "1   -0.045314                   0                0                  1   \n",
       "2   -0.045314                   0                0                  0   \n",
       "3   -0.045314                   0                0                  1   \n",
       "4   -0.045314                   0                0                  1   \n",
       "..        ...                 ...              ...                ...   \n",
       "483 -0.045314                   0                0                  1   \n",
       "484 -0.045314                   0                0                  1   \n",
       "485 -0.045314                   0                0                  1   \n",
       "486 -0.045314                   0                0                  0   \n",
       "487 -0.045314                   0                0                  0   \n",
       "\n",
       "     Source_snopes  Source_truthorfiction  RatingName  \n",
       "0                1                      0           0  \n",
       "1                0                      0           0  \n",
       "2                1                      0           0  \n",
       "3                0                      0           1  \n",
       "4                0                      0           0  \n",
       "..             ...                    ...         ...  \n",
       "483              0                      0           0  \n",
       "484              0                      0           0  \n",
       "485              0                      0           1  \n",
       "486              1                      0           0  \n",
       "487              1                      0           1  \n",
       "\n",
       "[488 rows x 3423 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfCleanHeadlineText2 = pd.DataFrame(tfidfVectorizer1.fit_transform(dfCleanHeadlineText2).toarray(), \n",
    "                                    columns = tfidfVectorizer1.get_feature_names())\n",
    "dfCleanHeadlineText2 = pd.DataFrame(standardScaler.fit_transform(dfCleanHeadlineText2), \n",
    "                                    columns = tfidfVectorizer1.get_feature_names())\n",
    "\n",
    "dfCleanSource2 = pd.get_dummies(dfCleanSource2, columns = ['Source'], prefix = 'Source').reset_index(drop = True)\n",
    "\n",
    "dfCleanRatingName2 = pd.DataFrame(classLabelEncoder.fit_transform(dfCleanRatingName2), columns = ['RatingName'])\n",
    "\n",
    "dfClean2 = pd.concat([dfCleanHeadlineText2, dfCleanSource2, dfCleanRatingName2], axis = 1)\n",
    "\n",
    "display(dfClean2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the transformed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfClean2.to_csv('attemps/tfclean2.csv', sep = ';', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "    <h2>\n",
    "        TF cleaned upsampled 2\n",
    "    </h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a copy of every column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCleanUpsampleHeadlineText2 = dfCleanUpsampleHeadlineText.copy()\n",
    "dfCleanUpsampleAuthor2 = dfCleanUpsampleAuthor.copy()\n",
    "dfCleanUpsampleNamedEntitiesClaim2 = dfCleanUpsampleNamedEntitiesClaim.copy()\n",
    "dfCleanUpsampleNamedEntitiesArticle2 = dfCleanUpsampleNamedEntitiesArticle.copy()\n",
    "dfCleanUpsampleKeywords2 = dfCleanUpsampleKeywords.copy()\n",
    "dfCleanUpsampleSource2 = dfCleanUpsampleSource.copy()\n",
    "dfCleanUpsampleRatingName2 = dfCleanUpsampleRatingName.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>05</th>\n",
       "      <th>1000</th>\n",
       "      <th>10000</th>\n",
       "      <th>100000</th>\n",
       "      <th>100k</th>\n",
       "      <th>101st</th>\n",
       "      <th>102000</th>\n",
       "      <th>106000</th>\n",
       "      <th>1270</th>\n",
       "      <th>150000</th>\n",
       "      <th>...</th>\n",
       "      <th>zimmerman</th>\n",
       "      <th>zipper</th>\n",
       "      <th>zippered</th>\n",
       "      <th>zuma</th>\n",
       "      <th>Source_africacheck</th>\n",
       "      <th>Source_factscan</th>\n",
       "      <th>Source_politifact</th>\n",
       "      <th>Source_snopes</th>\n",
       "      <th>Source_truthorfiction</th>\n",
       "      <th>RatingName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.074953</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.074953</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.052926</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.074953</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.074953</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.052926</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.074953</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.074953</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.052926</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.074953</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.074953</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.052926</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.074953</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.074953</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.052926</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>711</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.074953</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.074953</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.052926</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>712</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.074953</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.074953</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.052926</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>713</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.074953</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.074953</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.052926</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>714</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.074953</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.074953</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.052926</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>715</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.074953</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.074953</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.052926</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>716 rows × 3394 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           05      1000     10000    100000      100k     101st    102000  \\\n",
       "0   -0.037398 -0.037398 -0.074953 -0.037398 -0.037398 -0.037398 -0.037398   \n",
       "1   -0.037398 -0.037398 -0.074953 -0.037398 -0.037398 -0.037398 -0.037398   \n",
       "2   -0.037398 -0.037398 -0.074953 -0.037398 -0.037398 -0.037398 -0.037398   \n",
       "3   -0.037398 -0.037398 -0.074953 -0.037398 -0.037398 -0.037398 -0.037398   \n",
       "4   -0.037398 -0.037398 -0.074953 -0.037398 -0.037398 -0.037398 -0.037398   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "711 -0.037398 -0.037398 -0.074953 -0.037398 -0.037398 -0.037398 -0.037398   \n",
       "712 -0.037398 -0.037398 -0.074953 -0.037398 -0.037398 -0.037398 -0.037398   \n",
       "713 -0.037398 -0.037398 -0.074953 -0.037398 -0.037398 -0.037398 -0.037398   \n",
       "714 -0.037398 -0.037398 -0.074953 -0.037398 -0.037398 -0.037398 -0.037398   \n",
       "715 -0.037398 -0.037398 -0.074953 -0.037398 -0.037398 -0.037398 -0.037398   \n",
       "\n",
       "       106000      1270    150000  ...  zimmerman    zipper  zippered  \\\n",
       "0   -0.074953 -0.037398 -0.052926  ...  -0.037398 -0.037398 -0.037398   \n",
       "1   -0.074953 -0.037398 -0.052926  ...  -0.037398 -0.037398 -0.037398   \n",
       "2   -0.074953 -0.037398 -0.052926  ...  -0.037398 -0.037398 -0.037398   \n",
       "3   -0.074953 -0.037398 -0.052926  ...  -0.037398 -0.037398 -0.037398   \n",
       "4   -0.074953 -0.037398 -0.052926  ...  -0.037398 -0.037398 -0.037398   \n",
       "..        ...       ...       ...  ...        ...       ...       ...   \n",
       "711 -0.074953 -0.037398 -0.052926  ...  -0.037398 -0.037398 -0.037398   \n",
       "712 -0.074953 -0.037398 -0.052926  ...  -0.037398 -0.037398 -0.037398   \n",
       "713 -0.074953 -0.037398 -0.052926  ...  -0.037398 -0.037398 -0.037398   \n",
       "714 -0.074953 -0.037398 -0.052926  ...  -0.037398 -0.037398 -0.037398   \n",
       "715 -0.074953 -0.037398 -0.052926  ...  -0.037398 -0.037398 -0.037398   \n",
       "\n",
       "         zuma  Source_africacheck  Source_factscan  Source_politifact  \\\n",
       "0   -0.037398                   0                0                  0   \n",
       "1   -0.037398                   0                0                  0   \n",
       "2   -0.037398                   0                0                  0   \n",
       "3   -0.037398                   0                0                  1   \n",
       "4   -0.037398                   0                0                  1   \n",
       "..        ...                 ...              ...                ...   \n",
       "711 -0.037398                   0                0                  0   \n",
       "712 -0.037398                   0                0                  1   \n",
       "713 -0.037398                   0                0                  0   \n",
       "714 -0.037398                   0                0                  0   \n",
       "715 -0.037398                   0                0                  0   \n",
       "\n",
       "     Source_snopes  Source_truthorfiction  RatingName  \n",
       "0                1                      0           1  \n",
       "1                1                      0           0  \n",
       "2                1                      0           0  \n",
       "3                0                      0           1  \n",
       "4                0                      0           1  \n",
       "..             ...                    ...         ...  \n",
       "711              0                      1           1  \n",
       "712              0                      0           0  \n",
       "713              1                      0           1  \n",
       "714              1                      0           0  \n",
       "715              1                      0           1  \n",
       "\n",
       "[716 rows x 3394 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfCleanUpsampleHeadlineText2 = pd.DataFrame(tfidfVectorizer1.fit_transform(dfCleanUpsampleHeadlineText2).toarray(), \n",
    "                                            columns = tfidfVectorizer1.get_feature_names())\n",
    "dfCleanUpsampleHeadlineText2 = pd.DataFrame(standardScaler.fit_transform(dfCleanUpsampleHeadlineText2), \n",
    "                                            columns = tfidfVectorizer1.get_feature_names())\n",
    "\n",
    "dfCleanUpsampleSource2 = pd.get_dummies(dfCleanUpsampleSource2, \n",
    "                                        columns = ['Source'], prefix = 'Source').reset_index(drop = True)\n",
    "\n",
    "dfCleanUpsampleRatingName2 = pd.DataFrame(classLabelEncoder.fit_transform(dfCleanUpsampleRatingName2), \n",
    "                                          columns = ['RatingName'])\n",
    "\n",
    "dfCleanUpsample2 = pd.concat([dfCleanUpsampleHeadlineText2, dfCleanUpsampleSource2, \n",
    "                              dfCleanUpsampleRatingName2], axis = 1)\n",
    "\n",
    "display(dfCleanUpsample2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the transformed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCleanUpsample2.to_csv('attemps/tfcleanupsample2.csv', sep = ';', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "    <h2>\n",
    "        TF cleaned downsampled 2\n",
    "    </h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a copy of every column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCleanDownsampleHeadlineText2 = dfCleanDownsampleHeadlineText.copy()\n",
    "dfCleanDownsampleAuthor2 = dfCleanDownsampleAuthor.copy()\n",
    "dfCleanDownsampleNamedEntitiesClaim2 = dfCleanDownsampleNamedEntitiesClaim.copy()\n",
    "dfCleanDownsampleNamedEntitiesArticle2 = dfCleanDownsampleNamedEntitiesArticle.copy()\n",
    "dfCleanDownsampleKeywords2 = dfCleanDownsampleKeywords.copy()\n",
    "dfCleanDownsampleSource2 = dfCleanDownsampleSource.copy()\n",
    "dfCleanDownsampleRatingName2 = dfCleanDownsampleRatingName.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>05</th>\n",
       "      <th>10000</th>\n",
       "      <th>106000</th>\n",
       "      <th>150000</th>\n",
       "      <th>1729000000</th>\n",
       "      <th>17yearold</th>\n",
       "      <th>18000</th>\n",
       "      <th>1940s</th>\n",
       "      <th>200</th>\n",
       "      <th>20000</th>\n",
       "      <th>...</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>zambian</th>\n",
       "      <th>zimmerman</th>\n",
       "      <th>Source_africacheck</th>\n",
       "      <th>Source_factscan</th>\n",
       "      <th>Source_politifact</th>\n",
       "      <th>Source_snopes</th>\n",
       "      <th>Source_truthorfiction</th>\n",
       "      <th>RatingName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.136522</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.136522</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.136522</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.136522</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>16.093477</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.136522</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>255</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.136522</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>256</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.136522</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>257</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.136522</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>258</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.136522</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>259</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.136522</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>-0.062137</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>260 rows × 2182 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           05     10000    106000    150000  1729000000  17yearold     18000  \\\n",
       "0   -0.062137 -0.062137 -0.062137 -0.062137   -0.062137  -0.062137 -0.062137   \n",
       "1   -0.062137 -0.062137 -0.062137 -0.062137   -0.062137  -0.062137 -0.062137   \n",
       "2   -0.062137 -0.062137 -0.062137 -0.062137   -0.062137  -0.062137 -0.062137   \n",
       "3   -0.062137 -0.062137 -0.062137 -0.062137   -0.062137  -0.062137 -0.062137   \n",
       "4   -0.062137 -0.062137 -0.062137 -0.062137   -0.062137  -0.062137 -0.062137   \n",
       "..        ...       ...       ...       ...         ...        ...       ...   \n",
       "255 -0.062137 -0.062137 -0.062137 -0.062137   -0.062137  -0.062137 -0.062137   \n",
       "256 -0.062137 -0.062137 -0.062137 -0.062137   -0.062137  -0.062137 -0.062137   \n",
       "257 -0.062137 -0.062137 -0.062137 -0.062137   -0.062137  -0.062137 -0.062137   \n",
       "258 -0.062137 -0.062137 -0.062137 -0.062137   -0.062137  -0.062137 -0.062137   \n",
       "259 -0.062137 -0.062137 -0.062137 -0.062137   -0.062137  -0.062137 -0.062137   \n",
       "\n",
       "        1940s        200     20000  ...      york     young   zambian  \\\n",
       "0   -0.062137  -0.062137 -0.062137  ... -0.136522 -0.062137 -0.062137   \n",
       "1   -0.062137  -0.062137 -0.062137  ... -0.136522 -0.062137 -0.062137   \n",
       "2   -0.062137  -0.062137 -0.062137  ... -0.136522 -0.062137 -0.062137   \n",
       "3   -0.062137  -0.062137 -0.062137  ... -0.136522 -0.062137 -0.062137   \n",
       "4   -0.062137  16.093477 -0.062137  ... -0.136522 -0.062137 -0.062137   \n",
       "..        ...        ...       ...  ...       ...       ...       ...   \n",
       "255 -0.062137  -0.062137 -0.062137  ... -0.136522 -0.062137 -0.062137   \n",
       "256 -0.062137  -0.062137 -0.062137  ... -0.136522 -0.062137 -0.062137   \n",
       "257 -0.062137  -0.062137 -0.062137  ... -0.136522 -0.062137 -0.062137   \n",
       "258 -0.062137  -0.062137 -0.062137  ... -0.136522 -0.062137 -0.062137   \n",
       "259 -0.062137  -0.062137 -0.062137  ... -0.136522 -0.062137 -0.062137   \n",
       "\n",
       "     zimmerman  Source_africacheck  Source_factscan  Source_politifact  \\\n",
       "0    -0.062137                   0                0                  1   \n",
       "1    -0.062137                   0                0                  0   \n",
       "2    -0.062137                   0                0                  0   \n",
       "3    -0.062137                   0                0                  0   \n",
       "4    -0.062137                   0                0                  1   \n",
       "..         ...                 ...              ...                ...   \n",
       "255  -0.062137                   0                0                  1   \n",
       "256  -0.062137                   0                0                  1   \n",
       "257  -0.062137                   0                0                  1   \n",
       "258  -0.062137                   0                0                  1   \n",
       "259  -0.062137                   0                0                  0   \n",
       "\n",
       "     Source_snopes  Source_truthorfiction  RatingName  \n",
       "0                0                      0           0  \n",
       "1                1                      0           0  \n",
       "2                1                      0           0  \n",
       "3                1                      0           0  \n",
       "4                0                      0           0  \n",
       "..             ...                    ...         ...  \n",
       "255              0                      0           1  \n",
       "256              0                      0           1  \n",
       "257              0                      0           1  \n",
       "258              0                      0           1  \n",
       "259              1                      0           1  \n",
       "\n",
       "[260 rows x 2182 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfCleanDownsampleHeadlineText2 = pd.DataFrame(tfidfVectorizer1.fit_transform(dfCleanDownsampleHeadlineText2).toarray(), \n",
    "                                              columns = tfidfVectorizer1.get_feature_names())\n",
    "dfCleanDownsampleHeadlineText2 = pd.DataFrame(standardScaler.fit_transform(dfCleanDownsampleHeadlineText2), \n",
    "                                              columns = tfidfVectorizer1.get_feature_names())\n",
    "\n",
    "dfCleanDownsampleSource2 = pd.get_dummies(dfCleanDownsampleSource2, \n",
    "                                          columns = ['Source'], prefix = 'Source').reset_index(drop = True)\n",
    "\n",
    "dfCleanDownsampleRatingName2 = pd.DataFrame(classLabelEncoder.fit_transform(dfCleanDownsampleRatingName2), \n",
    "                                            columns = ['RatingName'])\n",
    "\n",
    "dfCleanDownsample2 = pd.concat([dfCleanDownsampleHeadlineText2, dfCleanDownsampleSource2, \n",
    "                                dfCleanDownsampleRatingName2], axis = 1)\n",
    "\n",
    "display(dfCleanDownsample2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the transformed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCleanDownsample2.to_csv('attemps/tfcleandownsample2.csv', sep = ';', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
