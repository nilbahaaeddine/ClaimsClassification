{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><h1> Projet Data Science </h1></div>\n",
    "<div align=\"center\"><h2> Classification d'assertions selon leur valeurs de véracité ( automatic fact-checking ) </h2></div>\n",
    "<h2>Membre du groupe</h2>\n",
    "<ul>\n",
    "    <li>Meriem AMERAOUI</li>\n",
    "    <li>Dounia BELABIOD</li>\n",
    "    <li>Jihene BOUHLEL</li>\n",
    "    <li>Bahaa Eddine NIL</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" align=\"center\">\n",
    "    <h1>\n",
    "        Executing the basic\n",
    "    </h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import pickle\n",
    "import warnings\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Compte rendu de classification\n",
    "def cpt_mal_classes(y_test_func, result_func):\n",
    "    nb_func = 0\n",
    "    for i in range(len(y_test_func)):\n",
    "        if y_test_func[i] != result_func[i]:\n",
    "            nb_func += 1\n",
    "    print (f'Taille des données {len(y_test_func)} mal classés {nb_func}\\n')\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category = FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" align=\"center\">\n",
    "    <h1>\n",
    "        Classification\n",
    "    </h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the transformed data for the classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('attemps/tf2.csv', sep = ';')\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the learning variables and the variable to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = df.values\n",
    "X = array[:,0:-1]\n",
    "y = array[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature extraction\n",
    "selectKBest = SelectKBest(score_func = f_classif,  k = df.shape[1]//2)\n",
    "selection = selectKBest.fit(X, y)\n",
    "print(selection.scores_)\n",
    "X_best = selection.transform(X)\n",
    "\n",
    "# summarize selected features\n",
    "display(pd.DataFrame(X_best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cut the data set into a test set and a learning set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myTrainSize = 0.3 # 30% du jeu de données pour le test\n",
    "myTestSize = 1 - myTrainSize # 70% du jeu de données pour l'entraînement\n",
    "seed = 30\n",
    "\n",
    "# Original X & y\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = myTrainSize, random_state = seed, test_size = myTestSize)\n",
    "\n",
    "# X & y after the features selection\n",
    "X_best_train, X_best_test, y_best_train, y_best_test = train_test_split(X_best, y, train_size = myTrainSize, random_state = seed, test_size = myTestSize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "    <h1>\n",
    "        Testing the first classifier\n",
    "    </h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GaussianNB classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfGaussianNB = GaussianNB()\n",
    "\n",
    "clfGaussianNB.fit(X_train, y_train)\n",
    "\n",
    "resultGaussianNB = clfGaussianNB.predict(X_test)\n",
    "\n",
    "print(f'accuracy : {accuracy_score(resultGaussianNB, y_test):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display the confusion matrix and the classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (f'Matrice de confusion :\\n{confusion_matrix(y_test, resultGaussianNB)}')\n",
    "print (f'Classification report :\\n{classification_report(y_test, resultGaussianNB)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validate with 10 splits (Kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7\n",
    "myKFold = KFold(n_splits = 10, shuffle = True, random_state = seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply the GaussianNB classifier and give the different accuracy for the 10 evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfGaussianNB = GaussianNB()\n",
    "\n",
    "myScoring = 'accuracy'\n",
    "\n",
    "score = cross_val_score(clfGaussianNB, X, y, cv = myKFold, scoring = myScoring)\n",
    "\n",
    "print(f'Les différentes accuracy pour les 10 évaluations sont :\\n{score}')\n",
    "print(f'Accuracy moyenne : {score.mean():.2f} | Standard deviation : {score.std():.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "    <h1>\n",
    "        Testing several classifiers\n",
    "    </h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "\n",
    "models.append(('KNN', KNeighborsClassifier()))      # GS Done\n",
    "models.append(('CART', DecisionTreeClassifier()))   # GS Done\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVC', SVC()))                       # GS Done\n",
    "models.append(('RFO', RandomForestClassifier()))    # GS Done\n",
    "models.append(('LR', LogisticRegression()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7\n",
    "myScoring = 'accuracy'\n",
    "scores = []\n",
    "names = []\n",
    "\n",
    "for name, model in models:\n",
    "    myKFold = KFold(n_splits = 10, random_state = seed)\n",
    "    startTime = time.time()\n",
    "    score = cross_val_score(model, X, y, cv = myKFold, scoring = myScoring)\n",
    "    endTime = time.time()\n",
    "    scores.append(score)\n",
    "    names.append(name)\n",
    "    print(f'{name}\\t({score.mean():.2f} | {score.std():.2f} | Time : {endTime - startTime:.2f})\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displaying results of the different classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "fig.suptitle('Comparaison des algorithmes')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(scores)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "scores = []\n",
    "names = []\n",
    "\n",
    "for name, model in models:\n",
    "    myKFold = KFold(n_splits = 10, shuffle = True, random_state = seed)\n",
    "    startTime = time.time()\n",
    "    score = cross_val_score(model, X, y, cv = myKFold, scoring = myScoring)\n",
    "    endTime = time.time()\n",
    "    scores.append(score)\n",
    "    names.append(name)\n",
    "    print(f'{name}\\t({score.mean():.2f} | {score.std():.2f} | Time : {endTime - startTime:.2f})\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displaying results of the different classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "fig.suptitle('Comparaison des algorithmes')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(scores)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply GridSearchCV to RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridParam = {'n_estimators': [4, 6, 9], \n",
    "             'max_features': ['log2', 'sqrt','auto'], \n",
    "             'criterion': ['entropy', 'gini'], \n",
    "             'max_depth': [2, 3, 5, 10], \n",
    "             'min_samples_split': [2, 3, 5], \n",
    "             'min_samples_leaf': [1, 5, 8]\n",
    "            }\n",
    "\n",
    "myScoring = 'accuracy'\n",
    "\n",
    "clfGridSearchCV = GridSearchCV(estimator = RandomForestClassifier(), param_grid = gridParam, scoring = myScoring, cv = 5, n_jobs = -1, iid = True, return_train_score = True)\n",
    "\n",
    "startTime = time.time()\n",
    "clfGridSearchCV.fit(X_train, y_train)\n",
    "endTime = time.time()\n",
    "\n",
    "print(f'temps : {endTime - startTime:.2f}')\n",
    "print(f'meilleur score : {clfGridSearchCV.best_score_:.2f}')\n",
    "print(f'meilleurs paramètres :\\n{clfGridSearchCV.best_params_}')\n",
    "print(f'meilleur estimateur :\\n{clfGridSearchCV.best_estimator_}')\n",
    "\n",
    "# tf1\n",
    "# {'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 6}\n",
    "# {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 6}\n",
    "# {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 9}\n",
    "# {'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 9}\n",
    "\n",
    "#tf2\n",
    "# {'criterion': 'gini', 'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 9}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply GridSearchCV to DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridParam = {'max_depth' : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \n",
    "             'criterion' : ['gini', 'entropy'], \n",
    "             'min_samples_leaf' : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "            }\n",
    "\n",
    "myScoring = 'accuracy'\n",
    "\n",
    "clfGridSearchCV = GridSearchCV(estimator = DecisionTreeClassifier(), param_grid = gridParam, scoring = myScoring, cv = 10, n_jobs = -1, iid = True, return_train_score = True)\n",
    "\n",
    "startTime = time.time()\n",
    "clfGridSearchCV.fit(X_train, y_train)\n",
    "endTime = time.time()\n",
    "\n",
    "print(f'temps : {endTime - startTime:.2f}')\n",
    "print(f'meilleur score : {clfGridSearchCV.best_score_:.2f}')\n",
    "print(f'meilleurs paramètres :\\n{clfGridSearchCV.best_params_}')\n",
    "print(f'meilleur estimateur :\\n{clfGridSearchCV.best_estimator_}')\n",
    "\n",
    "#tf1\n",
    "# {'criterion': 'entropy', 'max_depth': 8, 'min_samples_leaf': 1}\n",
    "# {'criterion': 'entropy', 'max_depth': 6, 'min_samples_leaf': 6}\n",
    "# {'criterion': 'entropy', 'max_depth': 9, 'min_samples_leaf': 5}\n",
    "# {'criterion': 'entropy', 'max_depth': 8, 'min_samples_leaf': 1}\n",
    "\n",
    "#tf2\n",
    "# {'criterion': 'entropy', 'max_depth': 8, 'min_samples_leaf': 4}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply GridSearchCV to SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridParam = {'C' : [0.001, 0.01, 0.1, 1, 10, 100, 1000], \n",
    "             'gamma' : ['scale', 0.0001, 0.001, 0.01, 0.1, 1], \n",
    "             'kernel' : ['linear', 'poly', 'rbf']\n",
    "            }\n",
    "\n",
    "myScoring = 'accuracy'\n",
    "\n",
    "clfGridSearchCV = GridSearchCV(estimator = SVC(), param_grid = gridParam, scoring = myScoring, cv = 5, n_jobs = 1, iid = True, return_train_score = True)\n",
    "\n",
    "startTime = time.time()\n",
    "clfGridSearchCV.fit(X_train, y_train)\n",
    "endTime = time.time()\n",
    "\n",
    "print(f'temps : {endTime - startTime:.2f}')\n",
    "print(f'meilleur score : {clfGridSearchCV.best_score_:.2f}')\n",
    "print(f'meilleurs paramètres :\\n{clfGridSearchCV.best_params_}')\n",
    "print(f'meilleur estimateur :\\n{clfGridSearchCV.best_estimator_}')\n",
    "\n",
    "#tf2\n",
    "# {'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply GridSearchCV to KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridParam = {'n_neighbors': list(range(1,15)), \n",
    "              'metric': ['minkowski', 'euclidean', 'manhattan']\n",
    "             }\n",
    "\n",
    "myScoring = 'accuracy'\n",
    "                        \n",
    "clfGridSearchCV = GridSearchCV(estimator = KNeighborsClassifier(), param_grid = gridParam, scoring = myScoring, cv = 5, n_jobs = -1, iid = True, return_train_score = True)\n",
    "\n",
    "startTime = time.time()\n",
    "clfGridSearchCV.fit(X_train, y_train)\n",
    "endTime = time.time()\n",
    "\n",
    "print(f'temps : {endTime - startTime:.2f}')\n",
    "print(f'meilleur score : {clfGridSearchCV.best_score_:.2f}')\n",
    "print(f'meilleurs paramètres :\\n{clfGridSearchCV.best_params_}')\n",
    "print(f'meilleur estimateur :\\n{clfGridSearchCV.best_estimator_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do a gridsearch taking the previous parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    'RandomForestClassifier': RandomForestClassifier(),\n",
    "    'DecisionTreeClassifier': DecisionTreeClassifier(),\n",
    "    'SVC': SVC(),\n",
    "    'KNeighborsClassifier': KNeighborsClassifier()\n",
    "}\n",
    "\n",
    "params = {\n",
    "    'RandomForestClassifier' : [\n",
    "        {'n_estimators' : [9, 6]}, \n",
    "        {'max_features' : ['auto', 'sqrt', 'log2']}, \n",
    "        {'criterion' : ['entropy', 'gini']}, \n",
    "        {'max_depth' : [10]}, \n",
    "        {'min_samples_split' : [2, 5]}, \n",
    "        {'min_samples_leaf' : [1, 5]}\n",
    "    ], \n",
    "    'DecisionTreeClassifier' : [\n",
    "        {'max_depth' : [9, 8]}, \n",
    "        {'criterion' : ['gini', 'entropy']}, \n",
    "        {'min_samples_leaf' : [1, 2, 3]}\n",
    "    ],\n",
    "    'SVC' : [\n",
    "        {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}, \n",
    "        {'gamma': ['scale', 0.0001, 0.001, 0.01, 0.1, 1]}, \n",
    "        {'kernel': ['linear', 'poly', 'rbf']}\n",
    "    ],\n",
    "    'KNeighborsClassifier' : [\n",
    "        {'metric': ['minkowski', 'manhattan']}, \n",
    "        {'n_neighbors': [1, 2]}\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Result:\n",
    "    def __init__(self, name, score, parameters, duration):\n",
    "        self.name = name\n",
    "        self.score = score\n",
    "        self.parameters = parameters\n",
    "        self.duration = duration\n",
    "    def __repr__(self):\n",
    "        return repr((self.name, self.score, self.parameters, self.duration))\n",
    "\n",
    "results = []\n",
    "myScoring = 'accuracy'\n",
    "\n",
    "for key, value in classifiers.items():\n",
    "    clfGridSearchCV = GridSearchCV(estimator = value, param_grid = params[key], scoring = myScoring, cv = 10, n_jobs = 1, iid = True)\n",
    "    startTime = time.time()\n",
    "    clfGridSearchCV.fit(X_train, y_train)\n",
    "    endTime = time.time()\n",
    "    result = Result(key, clfGridSearchCV.best_score_, clfGridSearchCV.best_estimator_, endTime - startTime)\n",
    "    results.append(result)\n",
    "\n",
    "results = sorted(results, key = lambda result: result.score, reverse = True)\n",
    "\n",
    "print(f'')\n",
    "print(f'Le meilleur resultat est celui du classifieur {results[0].name} :\\n\\tScore : {results[0].score:.2f}\\n\\tDuration : {results[0].duration:.2f}\\n\\tParameters :\\n\\t\\t{results[0].parameters}')\n",
    "\n",
    "print(f'\\nTous les résultats :\\n')\n",
    "for result in results:\n",
    "    print(f'\\t{result.name} classifier :\\n\\tScore : {result.score:.2f}\\n\\tDuration : {result.duration:.2f}\\n\\tParameters :\\n\\t\\t{result.parameters}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the best learned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(results[0].parameters, open('models/best.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reload the best model to test it with y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_loaded = pickle.load(open('models/best.sav', 'rb'))\n",
    "\n",
    "print(f'Modèle chargé :\\n{clf_loaded}\\n')\n",
    "\n",
    "result = clf_loaded.predict(X_test)\n",
    "\n",
    "cpt_mal_classes(y_test, result)\n",
    "\n",
    "print(f'Accuracy : {accuracy_score(result, y_test):.2f}\\n')\n",
    "print(f'Matrice de confusion :\\n{confusion_matrix(y_test, result)}\\n')\n",
    "print(f'Classification report :\\n{classification_report(y_test, result)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline = Pipeline([('scl', StandardScaler()), ('pca', PCA(n_components = 2)), ('clf', DecisionTreeClassifier(random_state = 42))])\n",
    "pipeline = Pipeline([('vect', LabelEncoder()), ('scl', StandardScaler()), ('clf', SVC())])\n",
    "\n",
    "t0 = time()\n",
    "print (\"Lancement du fit \\n\")\n",
    "pipeline.fit(X_train, y_train)\n",
    "print(\"Fit réalisé en %0.3fs\" % (time() - t0))\n",
    "t0 = time()\n",
    "print (\"Lancement de la prédiction \\n\")\n",
    "result = pipeline.predict(X_test)\n",
    "print(\"Prédiction réalisée en %0.3fs\" % (time() - t0))\n",
    "print('\\n accuracy:',accuracy_score(result, y_test),'\\n')\n",
    "conf = confusion_matrix(y_test, result)\n",
    "print ('\\n matrice de confusion \\n',conf)\n",
    "print ('\\n',classification_report(y_test, result))\n",
    "\n",
    "pickle.dump(pipeline, open('pipelines/thebestone.pkl', 'wb'))\n",
    "\n",
    "clf_loaded = pickle.load(open('pipelines/thebestone.pkl', 'rb'))\n",
    "print(f'Pipeline chargé :\\n{clf_loaded}\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
