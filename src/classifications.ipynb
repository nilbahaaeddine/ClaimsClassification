{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><h1> Projet Data Science </h1></div>\n",
    "<div align=\"center\"><h2> Classification d'assertions selon leur valeurs de véracité ( automatic fact-checking ) </h2></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" align=\"center\">\n",
    "    <h1>\n",
    "        Executing the basic\n",
    "    </h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import warnings\n",
    "import nltk\n",
    "import pickle\n",
    "import unicodedata\n",
    "import inflect\n",
    "import re\n",
    "import time\n",
    "import contractions\n",
    "\n",
    "from enum import Enum\n",
    "from functools import reduce\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.utils import resample\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category = FutureWarning)\n",
    "\n",
    "try:\n",
    "    nltk.data.find('corpora/stopwords')\n",
    "except LookupError:\n",
    "    nltk.download('stopwords')\n",
    "\n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "except LookupError:\n",
    "    nltk.download('punkt')\n",
    "    \n",
    "try:\n",
    "    nltk.data.find('corpora/wordnet')\n",
    "except LookupError:\n",
    "    nltk.download('wordnet')\n",
    "    \n",
    "try:\n",
    "    nltk.data.find('taggers/averaged_perceptron_tagger')\n",
    "except LookupError:\n",
    "    nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# Compte rendu de classification\n",
    "def cpt_mal_classes(y_test_func, result_func):\n",
    "    nb_func = 0\n",
    "    for i in range(len(y_test_func)):\n",
    "        if y_test_func[i] != result_func[i]:\n",
    "            nb_func += 1\n",
    "    print (f'Taille des données {len(y_test_func)} mal classés {nb_func}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" align=\"center\">\n",
    "    <h1>\n",
    "        Classification\n",
    "    </h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the transformed data for the classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abbott</th>\n",
       "      <th>abe</th>\n",
       "      <th>able</th>\n",
       "      <th>abortion</th>\n",
       "      <th>abruin</th>\n",
       "      <th>abuse</th>\n",
       "      <th>academy</th>\n",
       "      <th>accept</th>\n",
       "      <th>accepted</th>\n",
       "      <th>accepts</th>\n",
       "      <th>...</th>\n",
       "      <th>youn</th>\n",
       "      <th>yous</th>\n",
       "      <th>youth</th>\n",
       "      <th>yvette</th>\n",
       "      <th>zero</th>\n",
       "      <th>Source_africacheck</th>\n",
       "      <th>Source_politifact</th>\n",
       "      <th>Source_snopes</th>\n",
       "      <th>Source_truthorfiction</th>\n",
       "      <th>RatingName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-0.085331</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.084286</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.268617</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.20186</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.085331</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.084286</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.268617</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.20186</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-0.085331</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.084286</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.268617</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.20186</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-0.085331</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.084286</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.268617</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.20186</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-0.085331</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.084286</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.268617</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.20186</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>271</td>\n",
       "      <td>-0.085331</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.084286</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.268617</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.20186</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>272</td>\n",
       "      <td>-0.085331</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.084286</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.268617</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.20186</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>273</td>\n",
       "      <td>-0.085331</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.084286</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.268617</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.20186</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>274</td>\n",
       "      <td>-0.085331</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.084286</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.268617</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.20186</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>-0.085331</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.084286</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.268617</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>-0.20186</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>276 rows × 2180 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       abbott       abe      able  abortion    abruin     abuse   academy  \\\n",
       "0   -0.085331 -0.060302 -0.060302 -0.084286 -0.060302 -0.060302 -0.060302   \n",
       "1   -0.085331 -0.060302 -0.060302 -0.084286 -0.060302 -0.060302 -0.060302   \n",
       "2   -0.085331 -0.060302 -0.060302 -0.084286 -0.060302 -0.060302 -0.060302   \n",
       "3   -0.085331 -0.060302 -0.060302 -0.084286 -0.060302 -0.060302 -0.060302   \n",
       "4   -0.085331 -0.060302 -0.060302 -0.084286 -0.060302 -0.060302 -0.060302   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "271 -0.085331 -0.060302 -0.060302 -0.084286 -0.060302 -0.060302 -0.060302   \n",
       "272 -0.085331 -0.060302 -0.060302 -0.084286 -0.060302 -0.060302 -0.060302   \n",
       "273 -0.085331 -0.060302 -0.060302 -0.084286 -0.060302 -0.060302 -0.060302   \n",
       "274 -0.085331 -0.060302 -0.060302 -0.084286 -0.060302 -0.060302 -0.060302   \n",
       "275 -0.085331 -0.060302 -0.060302 -0.084286 -0.060302 -0.060302 -0.060302   \n",
       "\n",
       "       accept  accepted   accepts  ...      youn      yous     youth  \\\n",
       "0   -0.060302 -0.060302 -0.060302  ... -0.060302 -0.268617 -0.060302   \n",
       "1   -0.060302 -0.060302 -0.060302  ... -0.060302 -0.268617 -0.060302   \n",
       "2   -0.060302 -0.060302 -0.060302  ... -0.060302 -0.268617 -0.060302   \n",
       "3   -0.060302 -0.060302 -0.060302  ... -0.060302 -0.268617 -0.060302   \n",
       "4   -0.060302 -0.060302 -0.060302  ... -0.060302 -0.268617 -0.060302   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "271 -0.060302 -0.060302 -0.060302  ... -0.060302 -0.268617 -0.060302   \n",
       "272 -0.060302 -0.060302 -0.060302  ... -0.060302 -0.268617 -0.060302   \n",
       "273 -0.060302 -0.060302 -0.060302  ... -0.060302 -0.268617 -0.060302   \n",
       "274 -0.060302 -0.060302 -0.060302  ... -0.060302 -0.268617 -0.060302   \n",
       "275 -0.060302 -0.060302 -0.060302  ... -0.060302 -0.268617 -0.060302   \n",
       "\n",
       "       yvette     zero  Source_africacheck  Source_politifact  Source_snopes  \\\n",
       "0   -0.060302 -0.20186                   0                  0              1   \n",
       "1   -0.060302 -0.20186                   0                  0              1   \n",
       "2   -0.060302 -0.20186                   0                  0              1   \n",
       "3   -0.060302 -0.20186                   1                  0              0   \n",
       "4   -0.060302 -0.20186                   0                  0              1   \n",
       "..        ...      ...                 ...                ...            ...   \n",
       "271 -0.060302 -0.20186                   0                  1              0   \n",
       "272 -0.060302 -0.20186                   0                  0              1   \n",
       "273 -0.060302 -0.20186                   0                  1              0   \n",
       "274 -0.060302 -0.20186                   0                  1              0   \n",
       "275 -0.060302 -0.20186                   0                  1              0   \n",
       "\n",
       "     Source_truthorfiction  RatingName  \n",
       "0                        0           0  \n",
       "1                        0           0  \n",
       "2                        0           0  \n",
       "3                        0           0  \n",
       "4                        0           0  \n",
       "..                     ...         ...  \n",
       "271                      0           1  \n",
       "272                      0           1  \n",
       "273                      0           1  \n",
       "274                      0           1  \n",
       "275                      0           1  \n",
       "\n",
       "[276 rows x 2180 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('attemps/tfcleandownsample2.csv', sep = ';')\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the learning variables and the variable to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = df.values\n",
    "X = array[:,0:-1]\n",
    "y = array[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cut the data set into a test set and a learning set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "myTrainSize = 0.3 # 30% du jeu de données pour le test\n",
    "myTestSize = 1 - myTrainSize # 70% du jeu de données pour l'entraînement\n",
    "seed = 30\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = myTrainSize, random_state = seed, test_size = myTestSize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "    <h1>\n",
    "        Testing the first classifier on attemp 1\n",
    "    </h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GaussianNB classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.6581196581196581\n"
     ]
    }
   ],
   "source": [
    "clfGaussianNB = GaussianNB()\n",
    "\n",
    "clfGaussianNB.fit(X_train, y_train)\n",
    "\n",
    "resultGaussianNB = clfGaussianNB.predict(X_test)\n",
    "\n",
    "print(f'accuracy : {accuracy_score(resultGaussianNB, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display the confusion matrix and the classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice de confusion :\n",
      "[[210  42]\n",
      " [ 78  21]]\n",
      "Classification report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.83      0.78       252\n",
      "         1.0       0.33      0.21      0.26        99\n",
      "\n",
      "    accuracy                           0.66       351\n",
      "   macro avg       0.53      0.52      0.52       351\n",
      "weighted avg       0.62      0.66      0.63       351\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (f'Matrice de confusion :\\n{confusion_matrix(y_test, resultGaussianNB)}')\n",
    "print (f'Classification report :\\n{classification_report(y_test, resultGaussianNB)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validate with 10 splits (Kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7\n",
    "myKFold = KFold(n_splits = 10, shuffle = True, random_state = seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply the GaussianNB classifier and give the different accuracy for the 10 evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les différentes accuracy pour les 10 évaluations sont :\n",
      "[0.62745098 0.66       0.74       0.62       0.56       0.48\n",
      " 0.66       0.56       0.7        0.66      ]\n",
      "Accuracy moyenne : 0.6267450980392157 | Standard deviation : 0.07211140938382635\n"
     ]
    }
   ],
   "source": [
    "clfGaussianNB = GaussianNB()\n",
    "\n",
    "myScoring = 'accuracy'\n",
    "\n",
    "score = cross_val_score(clfGaussianNB, X, y, cv = myKFold, scoring = myScoring)\n",
    "\n",
    "print(f'Les différentes accuracy pour les 10 évaluations sont :\\n{score}')\n",
    "print(f'Accuracy moyenne : {score.mean()} | Standard deviation : {score.std()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "    <h1>\n",
    "        Testing several classifiers\n",
    "    </h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "\n",
    "models.append(('KNN', KNeighborsClassifier()))      # GS Done\n",
    "models.append(('CART', DecisionTreeClassifier()))   # GS Done\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVC', SVC()))                       # GS Done\n",
    "models.append(('RFO', RandomForestClassifier()))    # GS Done\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('LSVC', LinearSVC(dual = False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN\t(0.72 | 0.04 | Time : 1.97)\n",
      "\n",
      "CART\t(0.67 | 0.03 | Time : 3.90)\n",
      "\n",
      "NB\t(0.62 | 0.06 | Time : 0.72)\n",
      "\n",
      "SVC\t(0.72 | 0.04 | Time : 16.40)\n",
      "\n",
      "RFO\t(0.72 | 0.05 | Time : 1.56)\n",
      "\n",
      "LR\t(0.32 | 0.05 | Time : 4.17)\n",
      "\n",
      "LSVC\t(0.30 | 0.05 | Time : 103.85)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seed = 7\n",
    "myScoring = 'accuracy'\n",
    "scores = []\n",
    "names = []\n",
    "\n",
    "for name, model in models:\n",
    "    myKFold = KFold(n_splits = 10, random_state = seed)\n",
    "    startTime = time.time()\n",
    "    score = cross_val_score(model, X, y, cv = myKFold, scoring = myScoring)\n",
    "    endTime = time.time()\n",
    "    scores.append(score)\n",
    "    names.append(name)\n",
    "    print(f'{name}\\t({score.mean():.2f} | {score.std():.2f} | Time : {endTime - startTime:.2f})\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displaying results of the different classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "fig.suptitle('Comparaison des algorithmes')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(scores)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN\t(0.72 | 0.07 | Time : 2.56)\n",
      "\n",
      "CART\t(0.66 | 0.04 | Time : 5.77)\n",
      "\n",
      "NB\t(0.63 | 0.07 | Time : 0.63)\n",
      "\n",
      "SVC\t(0.72 | 0.07 | Time : 14.48)\n",
      "\n",
      "RFO\t(0.72 | 0.06 | Time : 1.05)\n",
      "\n",
      "LR\t(0.31 | 0.07 | Time : 2.92)\n",
      "\n",
      "LSVC\t(0.30 | 0.07 | Time : 123.43)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "names = []\n",
    "\n",
    "for name, model in models:\n",
    "    myKFold = KFold(n_splits = 10, shuffle = True, random_state = seed)\n",
    "    startTime = time.time()\n",
    "    score = cross_val_score(model, X, y, cv = myKFold, scoring = myScoring)\n",
    "    endTime = time.time()\n",
    "    scores.append(score)\n",
    "    names.append(name)\n",
    "    print(f'{name}\\t({score.mean():.2f} | {score.std():.2f} | Time : {endTime - startTime:.2f})\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displaying results of the different classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "fig.suptitle('Comparaison des algorithmes')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(scores)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply GridSearchCV to RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temps : 58.45\n",
      "meilleur score : 0.74\n",
      "meilleurs paramètres :\n",
      "{'criterion': 'entropy', 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 6}\n",
      "meilleur estimateur :\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "                       max_depth=3, max_features='sqrt', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=6,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "gridParam = {'n_estimators': [4, 6, 9], \n",
    "             'max_features': ['log2', 'sqrt','auto'], \n",
    "             'criterion': ['entropy', 'gini'], \n",
    "             'max_depth': [2, 3, 5, 10], \n",
    "             'min_samples_split': [2, 3, 5], \n",
    "             'min_samples_leaf': [1, 5, 8]\n",
    "            }\n",
    "\n",
    "myScoring = 'accuracy'\n",
    "\n",
    "clfGridSearchCV = GridSearchCV(estimator = RandomForestClassifier(), param_grid = gridParam, scoring = myScoring, cv = 5, n_jobs = -1, iid = True, return_train_score = True)\n",
    "\n",
    "startTime = time.time()\n",
    "clfGridSearchCV.fit(X_train, y_train)\n",
    "endTime = time.time()\n",
    "\n",
    "print(f'temps : {endTime - startTime:.2f}')\n",
    "print(f'meilleur score : {clfGridSearchCV.best_score_:.2f}')\n",
    "print(f'meilleurs paramètres :\\n{clfGridSearchCV.best_params_}')\n",
    "print(f'meilleur estimateur :\\n{clfGridSearchCV.best_estimator_}')\n",
    "\n",
    "# tf1\n",
    "# {'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 6}\n",
    "# {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 6}\n",
    "# {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 9}\n",
    "# {'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 9}\n",
    "\n",
    "#tf2\n",
    "# {'criterion': 'gini', 'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 9}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply GridSearchCV to DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temps : 25.84\n",
      "meilleur score : 0.73\n",
      "meilleurs paramètres :\n",
      "{'criterion': 'entropy', 'max_depth': 1, 'min_samples_leaf': 1}\n",
      "meilleur estimateur :\n",
      "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=1,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best')\n"
     ]
    }
   ],
   "source": [
    "gridParam = {'max_depth' : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \n",
    "             'criterion' : ['gini', 'entropy'], \n",
    "             'min_samples_leaf' : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "            }\n",
    "\n",
    "myScoring = 'accuracy'\n",
    "\n",
    "clfGridSearchCV = GridSearchCV(estimator = DecisionTreeClassifier(), param_grid = gridParam, scoring = myScoring, cv = 10, n_jobs = -1, iid = True, return_train_score = True)\n",
    "\n",
    "startTime = time.time()\n",
    "clfGridSearchCV.fit(X_train, y_train)\n",
    "endTime = time.time()\n",
    "\n",
    "print(f'temps : {endTime - startTime:.2f}')\n",
    "print(f'meilleur score : {clfGridSearchCV.best_score_:.2f}')\n",
    "print(f'meilleurs paramètres :\\n{clfGridSearchCV.best_params_}')\n",
    "print(f'meilleur estimateur :\\n{clfGridSearchCV.best_estimator_}')\n",
    "\n",
    "#tf1\n",
    "# {'criterion': 'entropy', 'max_depth': 8, 'min_samples_leaf': 1}\n",
    "# {'criterion': 'entropy', 'max_depth': 6, 'min_samples_leaf': 6}\n",
    "# {'criterion': 'entropy', 'max_depth': 9, 'min_samples_leaf': 5}\n",
    "# {'criterion': 'entropy', 'max_depth': 8, 'min_samples_leaf': 1}\n",
    "\n",
    "#tf2\n",
    "# {'criterion': 'entropy', 'max_depth': 8, 'min_samples_leaf': 4}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply GridSearchCV to SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temps : 166.85\n",
      "meilleur score : 0.73\n",
      "meilleurs paramètres :\n",
      "{'C': 0.001, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "meilleur estimateur :\n",
      "SVC(C=0.001, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "gridParam = {'C' : [0.001, 0.01, 0.1, 1, 10, 100, 1000], \n",
    "             'gamma' : ['scale', 0.0001, 0.001, 0.01, 0.1, 1], \n",
    "             'kernel' : ['linear', 'poly', 'rbf']\n",
    "            }\n",
    "\n",
    "myScoring = 'accuracy'\n",
    "\n",
    "clfGridSearchCV = GridSearchCV(estimator = SVC(), param_grid = gridParam, scoring = myScoring, cv = 5, n_jobs = 1, iid = True, return_train_score = True)\n",
    "\n",
    "startTime = time.time()\n",
    "clfGridSearchCV.fit(X_train, y_train)\n",
    "endTime = time.time()\n",
    "\n",
    "print(f'temps : {endTime - startTime:.2f}')\n",
    "print(f'meilleur score : {clfGridSearchCV.best_score_:.2f}')\n",
    "print(f'meilleurs paramètres :\\n{clfGridSearchCV.best_params_}')\n",
    "print(f'meilleur estimateur :\\n{clfGridSearchCV.best_estimator_}')\n",
    "\n",
    "#tf2\n",
    "# {'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply GridSearchCV to KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temps : 17.60\n",
      "meilleur score : 0.73\n",
      "meilleurs paramètres :\n",
      "{'metric': 'minkowski', 'n_neighbors': 2}\n",
      "meilleur estimateur :\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=2, p=2,\n",
      "                     weights='uniform')\n"
     ]
    }
   ],
   "source": [
    "gridParam = {'n_neighbors': list(range(1,15)), \n",
    "              'metric': ['minkowski', 'euclidean', 'manhattan']\n",
    "             }\n",
    "\n",
    "myScoring = 'accuracy'\n",
    "                        \n",
    "clfGridSearchCV = GridSearchCV(estimator = KNeighborsClassifier(), param_grid = gridParam, scoring = myScoring, cv = 5, n_jobs = -1, iid = True, return_train_score = True)\n",
    "\n",
    "startTime = time.time()\n",
    "clfGridSearchCV.fit(X_train, y_train)\n",
    "endTime = time.time()\n",
    "\n",
    "print(f'temps : {endTime - startTime:.2f}')\n",
    "print(f'meilleur score : {clfGridSearchCV.best_score_:.2f}')\n",
    "print(f'meilleurs paramètres :\\n{clfGridSearchCV.best_params_}')\n",
    "print(f'meilleur estimateur :\\n{clfGridSearchCV.best_estimator_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do a gridsearch taking the previous parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    'RandomForestClassifier': RandomForestClassifier(),\n",
    "    'DecisionTreeClassifier': DecisionTreeClassifier(),\n",
    "    'SVC': SVC(),\n",
    "    'KNeighborsClassifier': KNeighborsClassifier()\n",
    "}\n",
    "\n",
    "params = {\n",
    "    'RandomForestClassifier' : [\n",
    "        {'n_estimators' : [9, 6]}, \n",
    "        {'max_features' : ['auto', 'sqrt', 'log2']}, \n",
    "        {'criterion' : ['entropy', 'gini']}, \n",
    "        {'max_depth' : [10]}, \n",
    "        {'min_samples_split' : [2, 5]}, \n",
    "        {'min_samples_leaf' : [1, 5]}\n",
    "    ], \n",
    "    'DecisionTreeClassifier' : [\n",
    "        {'max_depth' : [9, 8]}, \n",
    "        {'criterion' : ['gini', 'entropy']}, \n",
    "        {'min_samples_leaf' : [1, 2, 3]}\n",
    "    ],\n",
    "    'SVC' : [\n",
    "        {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}, \n",
    "        {'gamma': ['scale', 0.0001, 0.001, 0.01, 0.1, 1]}, \n",
    "        {'kernel': ['linear', 'poly', 'rbf']}\n",
    "    ],\n",
    "    'KNeighborsClassifier' : [\n",
    "        {'metric': ['minkowski', 'manhattan']}, \n",
    "        {'n_neighbors': [1, 2]}\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Le meilleur resultat est celui du classifieur RandomForestClassifier :\n",
      "\tScore : 0.74\n",
      "\tDuration : 6.87\n",
      "\tParameters :\n",
      "\t\tRandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='log2', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n",
      "\n",
      "Tous les résultats :\n",
      "\n",
      "\tRandomForestClassifier classifier :\n",
      "\tScore : 0.74\n",
      "\tDuration : 6.87\n",
      "\tParameters :\n",
      "\t\tRandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='log2', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n",
      "\n",
      "\tSVC classifier :\n",
      "\tScore : 0.73\n",
      "\tDuration : 19.27\n",
      "\tParameters :\n",
      "\t\tSVC(C=0.001, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "\n",
      "\tKNeighborsClassifier classifier :\n",
      "\tScore : 0.73\n",
      "\tDuration : 1.00\n",
      "\tParameters :\n",
      "\t\tKNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "                     weights='uniform')\n",
      "\n",
      "\tDecisionTreeClassifier classifier :\n",
      "\tScore : 0.63\n",
      "\tDuration : 1.37\n",
      "\tParameters :\n",
      "\t\tDecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=9,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class Result:\n",
    "    def __init__(self, name, score, parameters, duration):\n",
    "        self.name = name\n",
    "        self.score = score\n",
    "        self.parameters = parameters\n",
    "        self.duration = duration\n",
    "    def __repr__(self):\n",
    "        return repr((self.name, self.score, self.parameters, self.duration))\n",
    "\n",
    "results = []\n",
    "myScoring = 'accuracy'\n",
    "\n",
    "for key, value in classifiers.items():\n",
    "    clfGridSearchCV = GridSearchCV(estimator = value, param_grid = params[key], scoring = myScoring, cv = 10, n_jobs = 1, iid = True)\n",
    "    startTime = time.time()\n",
    "    clfGridSearchCV.fit(X_train, y_train)\n",
    "    endTime = time.time()\n",
    "    result = Result(key, clfGridSearchCV.best_score_, clfGridSearchCV.best_estimator_, endTime - startTime)\n",
    "    results.append(result)\n",
    "\n",
    "results = sorted(results, key = lambda result: result.score, reverse = True)\n",
    "\n",
    "print(f'')\n",
    "print(f'Le meilleur resultat est celui du classifieur {results[0].name} :\\n\\tScore : {results[0].score:.2f}\\n\\tDuration : {results[0].duration:.2f}\\n\\tParameters :\\n\\t\\t{results[0].parameters}')\n",
    "\n",
    "print(f'\\nTous les résultats :\\n')\n",
    "for result in results:\n",
    "    print(f'\\t{result.name} classifier :\\n\\tScore : {result.score:.2f}\\n\\tDuration : {result.duration:.2f}\\n\\tParameters :\\n\\t\\t{result.parameters}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the best learned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(results[0].parameters, open('modeles/best.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline = Pipeline([('scl', StandardScaler()), ('pca', PCA(n_components = 2)), ('clf', DecisionTreeClassifier(random_state = 42))])\n",
    "#pipeline = Pipeline([('vect', MinMaxScaler()), ('clf', SVC(gamma = 'scale'))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reload the best model to test it with y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle chargé :\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='log2', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n",
      "\n",
      "Taille des données 351 mal classés 99\n",
      "\n",
      "Accuracy : 0.72\n",
      "\n",
      "Matrice de confusion :\n",
      "[[250   2]\n",
      " [ 97   2]]\n",
      "\n",
      "Classification report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.99      0.83       252\n",
      "         1.0       0.50      0.02      0.04        99\n",
      "\n",
      "    accuracy                           0.72       351\n",
      "   macro avg       0.61      0.51      0.44       351\n",
      "weighted avg       0.66      0.72      0.61       351\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_loaded = pickle.load(open('modeles/best.sav', 'rb'))\n",
    "\n",
    "print(f'Modèle chargé :\\n{clf_loaded}\\n')\n",
    "\n",
    "result = clf_loaded.predict(X_test)\n",
    "\n",
    "cpt_mal_classes(y_test, result)\n",
    "\n",
    "print(f'Accuracy : {accuracy_score(result, y_test):.2f}\\n')\n",
    "print(f'Matrice de confusion :\\n{confusion_matrix(y_test, result)}\\n')\n",
    "print(f'Classification report :\\n{classification_report(y_test, result)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
