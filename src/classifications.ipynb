{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><h1> Data Science Project </h1></div>\n",
    "<div align=\"center\"><h2> Classification of assertions according to their veracity values ( automatic fact-checking ) </h2></div>\n",
    "<h2>Group member</h2>\n",
    "<ul>\n",
    "    <li>Meriem AMERAOUI</li>\n",
    "    <li>Dounia BELABIOD</li>\n",
    "    <li>Jihene BOUHLEL</li>\n",
    "    <li>Bahaa Eddine NIL</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" align=\"center\">\n",
    "    <h1>\n",
    "        Basics\n",
    "    </h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import pickle\n",
    "import warnings\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Compte rendu de classification\n",
    "def cpt_mal_classes(y_test_func, result_func):\n",
    "    nb_func = 0\n",
    "    for i in range(len(y_test_func)):\n",
    "        if y_test_func[i] != result_func[i]:\n",
    "            nb_func += 1\n",
    "    print (f'Taille des données {len(y_test_func)} mal classés {nb_func}\\n')\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category = FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" align=\"center\">\n",
    "    <h1>\n",
    "        Classification\n",
    "    </h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the transformed data for the classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>05</th>\n",
       "      <th>1000</th>\n",
       "      <th>10000</th>\n",
       "      <th>100000</th>\n",
       "      <th>100k</th>\n",
       "      <th>101st</th>\n",
       "      <th>102000</th>\n",
       "      <th>106000</th>\n",
       "      <th>1270</th>\n",
       "      <th>150000</th>\n",
       "      <th>...</th>\n",
       "      <th>zimmerman</th>\n",
       "      <th>zipper</th>\n",
       "      <th>zippered</th>\n",
       "      <th>zuma</th>\n",
       "      <th>Source_africacheck</th>\n",
       "      <th>Source_factscan</th>\n",
       "      <th>Source_politifact</th>\n",
       "      <th>Source_snopes</th>\n",
       "      <th>Source_truthorfiction</th>\n",
       "      <th>RatingName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.074953</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.074953</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.052926</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.074953</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.074953</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.052926</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.074953</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.074953</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.052926</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.074953</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.074953</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.052926</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.074953</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.074953</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.052926</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>711</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.074953</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.074953</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.052926</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>712</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.074953</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.074953</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.052926</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>713</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.074953</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.074953</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.052926</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>714</td>\n",
       "      <td>26.739484</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.074953</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.074953</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.052926</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>715</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.074953</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.074953</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.052926</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>716 rows × 3394 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            05      1000     10000    100000      100k     101st    102000  \\\n",
       "0    -0.037398 -0.037398 -0.074953 -0.037398 -0.037398 -0.037398 -0.037398   \n",
       "1    -0.037398 -0.037398 -0.074953 -0.037398 -0.037398 -0.037398 -0.037398   \n",
       "2    -0.037398 -0.037398 -0.074953 -0.037398 -0.037398 -0.037398 -0.037398   \n",
       "3    -0.037398 -0.037398 -0.074953 -0.037398 -0.037398 -0.037398 -0.037398   \n",
       "4    -0.037398 -0.037398 -0.074953 -0.037398 -0.037398 -0.037398 -0.037398   \n",
       "..         ...       ...       ...       ...       ...       ...       ...   \n",
       "711  -0.037398 -0.037398 -0.074953 -0.037398 -0.037398 -0.037398 -0.037398   \n",
       "712  -0.037398 -0.037398 -0.074953 -0.037398 -0.037398 -0.037398 -0.037398   \n",
       "713  -0.037398 -0.037398 -0.074953 -0.037398 -0.037398 -0.037398 -0.037398   \n",
       "714  26.739484 -0.037398 -0.074953 -0.037398 -0.037398 -0.037398 -0.037398   \n",
       "715  -0.037398 -0.037398 -0.074953 -0.037398 -0.037398 -0.037398 -0.037398   \n",
       "\n",
       "       106000      1270    150000  ...  zimmerman    zipper  zippered  \\\n",
       "0   -0.074953 -0.037398 -0.052926  ...  -0.037398 -0.037398 -0.037398   \n",
       "1   -0.074953 -0.037398 -0.052926  ...  -0.037398 -0.037398 -0.037398   \n",
       "2   -0.074953 -0.037398 -0.052926  ...  -0.037398 -0.037398 -0.037398   \n",
       "3   -0.074953 -0.037398 -0.052926  ...  -0.037398 -0.037398 -0.037398   \n",
       "4   -0.074953 -0.037398 -0.052926  ...  -0.037398 -0.037398 -0.037398   \n",
       "..        ...       ...       ...  ...        ...       ...       ...   \n",
       "711 -0.074953 -0.037398 -0.052926  ...  -0.037398 -0.037398 -0.037398   \n",
       "712 -0.074953 -0.037398 -0.052926  ...  -0.037398 -0.037398 -0.037398   \n",
       "713 -0.074953 -0.037398 -0.052926  ...  -0.037398 -0.037398 -0.037398   \n",
       "714 -0.074953 -0.037398 -0.052926  ...  -0.037398 -0.037398 -0.037398   \n",
       "715 -0.074953 -0.037398 -0.052926  ...  -0.037398 -0.037398 -0.037398   \n",
       "\n",
       "         zuma  Source_africacheck  Source_factscan  Source_politifact  \\\n",
       "0   -0.037398                   0                0                  0   \n",
       "1   -0.037398                   0                0                  1   \n",
       "2   -0.037398                   0                0                  1   \n",
       "3   -0.037398                   0                0                  1   \n",
       "4   -0.037398                   1                0                  0   \n",
       "..        ...                 ...              ...                ...   \n",
       "711 -0.037398                   0                0                  1   \n",
       "712 -0.037398                   0                0                  0   \n",
       "713 -0.037398                   0                0                  0   \n",
       "714 -0.037398                   1                0                  0   \n",
       "715 -0.037398                   0                0                  0   \n",
       "\n",
       "     Source_snopes  Source_truthorfiction  RatingName  \n",
       "0                1                      0           0  \n",
       "1                0                      0           1  \n",
       "2                0                      0           1  \n",
       "3                0                      0           1  \n",
       "4                0                      0           0  \n",
       "..             ...                    ...         ...  \n",
       "711              0                      0           1  \n",
       "712              1                      0           0  \n",
       "713              1                      0           1  \n",
       "714              0                      0           0  \n",
       "715              1                      0           0  \n",
       "\n",
       "[716 rows x 3394 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('attemps/tfcleanupsample2.csv', sep = ';')\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the learning variables and the variable to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = df.values\n",
    "X = array[:,0:-1]\n",
    "y = array[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.          1.          4.03389831 ... 44.87623935 43.84397728\n",
      "  0.07813526]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1687</th>\n",
       "      <th>1688</th>\n",
       "      <th>1689</th>\n",
       "      <th>1690</th>\n",
       "      <th>1691</th>\n",
       "      <th>1692</th>\n",
       "      <th>1693</th>\n",
       "      <th>1694</th>\n",
       "      <th>1695</th>\n",
       "      <th>1696</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-0.074953</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.074953</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.052926</td>\n",
       "      <td>-0.064866</td>\n",
       "      <td>-0.083859</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.064866</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.196071</td>\n",
       "      <td>-0.189026</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.064866</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.074953</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.074953</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.074953</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.052926</td>\n",
       "      <td>-0.064866</td>\n",
       "      <td>-0.083859</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.064866</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.196071</td>\n",
       "      <td>-0.189026</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.064866</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.074953</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-0.074953</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.074953</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.052926</td>\n",
       "      <td>-0.064866</td>\n",
       "      <td>-0.083859</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.064866</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.196071</td>\n",
       "      <td>-0.189026</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.064866</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.074953</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-0.074953</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.074953</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.052926</td>\n",
       "      <td>-0.064866</td>\n",
       "      <td>-0.083859</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.064866</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.196071</td>\n",
       "      <td>-0.189026</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.064866</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.074953</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-0.074953</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.074953</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.052926</td>\n",
       "      <td>-0.064866</td>\n",
       "      <td>-0.083859</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.064866</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.196071</td>\n",
       "      <td>-0.189026</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.064866</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.074953</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>711</td>\n",
       "      <td>-0.074953</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.074953</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.052926</td>\n",
       "      <td>-0.064866</td>\n",
       "      <td>-0.083859</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.064866</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.196071</td>\n",
       "      <td>-0.189026</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.064866</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.074953</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>712</td>\n",
       "      <td>-0.074953</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.074953</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.052926</td>\n",
       "      <td>-0.064866</td>\n",
       "      <td>-0.083859</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.064866</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.196071</td>\n",
       "      <td>-0.189026</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.064866</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.074953</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>713</td>\n",
       "      <td>-0.074953</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.074953</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.052926</td>\n",
       "      <td>-0.064866</td>\n",
       "      <td>-0.083859</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.064866</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.196071</td>\n",
       "      <td>-0.189026</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.064866</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.074953</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>714</td>\n",
       "      <td>-0.074953</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.074953</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.052926</td>\n",
       "      <td>-0.064866</td>\n",
       "      <td>-0.083859</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.064866</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.196071</td>\n",
       "      <td>-0.189026</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.064866</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.074953</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>715</td>\n",
       "      <td>-0.074953</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.074953</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.052926</td>\n",
       "      <td>-0.064866</td>\n",
       "      <td>-0.083859</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.064866</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.196071</td>\n",
       "      <td>-0.189026</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.064866</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.037398</td>\n",
       "      <td>-0.074953</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>716 rows × 1697 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6     \\\n",
       "0   -0.074953 -0.037398 -0.037398 -0.074953 -0.037398 -0.052926 -0.064866   \n",
       "1   -0.074953 -0.037398 -0.037398 -0.074953 -0.037398 -0.052926 -0.064866   \n",
       "2   -0.074953 -0.037398 -0.037398 -0.074953 -0.037398 -0.052926 -0.064866   \n",
       "3   -0.074953 -0.037398 -0.037398 -0.074953 -0.037398 -0.052926 -0.064866   \n",
       "4   -0.074953 -0.037398 -0.037398 -0.074953 -0.037398 -0.052926 -0.064866   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "711 -0.074953 -0.037398 -0.037398 -0.074953 -0.037398 -0.052926 -0.064866   \n",
       "712 -0.074953 -0.037398 -0.037398 -0.074953 -0.037398 -0.052926 -0.064866   \n",
       "713 -0.074953 -0.037398 -0.037398 -0.074953 -0.037398 -0.052926 -0.064866   \n",
       "714 -0.074953 -0.037398 -0.037398 -0.074953 -0.037398 -0.052926 -0.064866   \n",
       "715 -0.074953 -0.037398 -0.037398 -0.074953 -0.037398 -0.052926 -0.064866   \n",
       "\n",
       "         7         8         9     ...      1687      1688      1689  \\\n",
       "0   -0.083859 -0.037398 -0.064866  ... -0.196071 -0.189026 -0.037398   \n",
       "1   -0.083859 -0.037398 -0.064866  ... -0.196071 -0.189026 -0.037398   \n",
       "2   -0.083859 -0.037398 -0.064866  ... -0.196071 -0.189026 -0.037398   \n",
       "3   -0.083859 -0.037398 -0.064866  ... -0.196071 -0.189026 -0.037398   \n",
       "4   -0.083859 -0.037398 -0.064866  ... -0.196071 -0.189026 -0.037398   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "711 -0.083859 -0.037398 -0.064866  ... -0.196071 -0.189026 -0.037398   \n",
       "712 -0.083859 -0.037398 -0.064866  ... -0.196071 -0.189026 -0.037398   \n",
       "713 -0.083859 -0.037398 -0.064866  ... -0.196071 -0.189026 -0.037398   \n",
       "714 -0.083859 -0.037398 -0.064866  ... -0.196071 -0.189026 -0.037398   \n",
       "715 -0.083859 -0.037398 -0.064866  ... -0.196071 -0.189026 -0.037398   \n",
       "\n",
       "         1690      1691      1692      1693      1694  1695  1696  \n",
       "0   -0.064866 -0.037398 -0.037398 -0.037398 -0.074953   0.0   1.0  \n",
       "1   -0.064866 -0.037398 -0.037398 -0.037398 -0.074953   1.0   0.0  \n",
       "2   -0.064866 -0.037398 -0.037398 -0.037398 -0.074953   1.0   0.0  \n",
       "3   -0.064866 -0.037398 -0.037398 -0.037398 -0.074953   1.0   0.0  \n",
       "4   -0.064866 -0.037398 -0.037398 -0.037398 -0.074953   0.0   0.0  \n",
       "..        ...       ...       ...       ...       ...   ...   ...  \n",
       "711 -0.064866 -0.037398 -0.037398 -0.037398 -0.074953   1.0   0.0  \n",
       "712 -0.064866 -0.037398 -0.037398 -0.037398 -0.074953   0.0   1.0  \n",
       "713 -0.064866 -0.037398 -0.037398 -0.037398 -0.074953   0.0   1.0  \n",
       "714 -0.064866 -0.037398 -0.037398 -0.037398 -0.074953   0.0   0.0  \n",
       "715 -0.064866 -0.037398 -0.037398 -0.037398 -0.074953   0.0   1.0  \n",
       "\n",
       "[716 rows x 1697 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# feature extraction\n",
    "selectKBest = SelectKBest(score_func = f_classif,  k = df.shape[1]//2)\n",
    "selection = selectKBest.fit(X, y)\n",
    "print(selection.scores_)\n",
    "X_best = selection.transform(X)\n",
    "\n",
    "# summarize selected features\n",
    "display(pd.DataFrame(X_best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cut the data set into a test set and a learning set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "myTrainSize = 0.3 # 30% du jeu de données pour le test\n",
    "myTestSize = 1 - myTrainSize # 70% du jeu de données pour l'entraînement\n",
    "seed = 30\n",
    "\n",
    "# Original X & y\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = myTrainSize, \n",
    "                                                    random_state = seed, test_size = myTestSize)\n",
    "\n",
    "# X & y after the features selection\n",
    "X_best_train, X_best_test, y_best_train, y_best_test = train_test_split(X_best, y, train_size = myTrainSize, \n",
    "                                                                        random_state = seed, test_size = myTestSize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "    <h1>\n",
    "        Testing the first classifier\n",
    "    </h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GaussianNB classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.74\n"
     ]
    }
   ],
   "source": [
    "clfGaussianNB = GaussianNB()\n",
    "\n",
    "clfGaussianNB.fit(X_train, y_train)\n",
    "\n",
    "resultGaussianNB = clfGaussianNB.predict(X_test)\n",
    "\n",
    "print(f'accuracy : {accuracy_score(resultGaussianNB, y_test):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display the confusion matrix and the classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice de confusion :\n",
      "[[174  72]\n",
      " [ 59 197]]\n",
      "Classification report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.71      0.73       246\n",
      "         1.0       0.73      0.77      0.75       256\n",
      "\n",
      "    accuracy                           0.74       502\n",
      "   macro avg       0.74      0.74      0.74       502\n",
      "weighted avg       0.74      0.74      0.74       502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (f'Matrice de confusion :\\n{confusion_matrix(y_test, resultGaussianNB)}')\n",
    "print (f'Classification report :\\n{classification_report(y_test, resultGaussianNB)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validate with 10 splits (Kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7\n",
    "myKFold = KFold(n_splits = 10, shuffle = True, random_state = seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply the GaussianNB classifier and give the different accuracy for the 10 evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les différentes accuracy pour les 10 évaluations sont :\n",
      "[0.86111111 0.94444444 0.97222222 0.90277778 0.80555556 0.86111111\n",
      " 0.85915493 0.85915493 0.85915493 0.88732394]\n",
      "Accuracy moyenne : 0.88 | Standard deviation : 0.05\n"
     ]
    }
   ],
   "source": [
    "clfGaussianNB = GaussianNB()\n",
    "\n",
    "myScoring = 'accuracy'\n",
    "\n",
    "score = cross_val_score(clfGaussianNB, X, y, cv = myKFold, scoring = myScoring)\n",
    "\n",
    "print(f'Les différentes accuracy pour les 10 évaluations sont :\\n{score}')\n",
    "print(f'Accuracy moyenne : {score.mean():.2f} | Standard deviation : {score.std():.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "    <h1>\n",
    "        Testing several classifiers\n",
    "    </h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVC', SVC()))\n",
    "models.append(('RFO', RandomForestClassifier()))\n",
    "models.append(('LR', LogisticRegression()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN\t(0.50 | 0.05 | Time : 3.97)\n",
      "\n",
      "CART\t(0.86 | 0.04 | Time : 2.28)\n",
      "\n",
      "NB\t(0.89 | 0.04 | Time : 0.81)\n",
      "\n",
      "SVC\t(0.94 | 0.02 | Time : 12.59)\n",
      "\n",
      "RFO\t(0.96 | 0.01 | Time : 1.23)\n",
      "\n",
      "LR\t(0.90 | 0.04 | Time : 2.70)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seed = 7\n",
    "myScoring = 'accuracy'\n",
    "scores = []\n",
    "names = []\n",
    "\n",
    "for name, model in models:\n",
    "    myKFold = KFold(n_splits = 10, random_state = seed)\n",
    "    startTime = time.time()\n",
    "    score = cross_val_score(model, X, y, cv = myKFold, scoring = myScoring)\n",
    "    endTime = time.time()\n",
    "    scores.append(score)\n",
    "    names.append(name)\n",
    "    print(f'{name}\\t({score.mean():.2f} | {score.std():.2f} | Time : {endTime - startTime:.2f})\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displaying results of the different classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "fig.suptitle('Comparaison des algorithmes')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(scores)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN\t(0.50 | 0.05 | Time : 3.73)\n",
      "\n",
      "CART\t(0.85 | 0.04 | Time : 2.44)\n",
      "\n",
      "NB\t(0.88 | 0.05 | Time : 0.78)\n",
      "\n",
      "SVC\t(0.93 | 0.03 | Time : 12.50)\n",
      "\n",
      "RFO\t(0.93 | 0.04 | Time : 1.16)\n",
      "\n",
      "LR\t(0.89 | 0.05 | Time : 2.99)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "names = []\n",
    "\n",
    "for name, model in models:\n",
    "    myKFold = KFold(n_splits = 10, shuffle = True, random_state = seed)\n",
    "    startTime = time.time()\n",
    "    score = cross_val_score(model, X, y, cv = myKFold, scoring = myScoring)\n",
    "    endTime = time.time()\n",
    "    scores.append(score)\n",
    "    names.append(name)\n",
    "    print(f'{name}\\t({score.mean():.2f} | {score.std():.2f} | Time : {endTime - startTime:.2f})\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displaying results of the different classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "fig.suptitle('Comparaison des algorithmes')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(scores)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply GridSearchCV to RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temps : 45.10\n",
      "meilleur score : 0.69\n",
      "meilleurs paramètres :\n",
      "{'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 9}\n",
      "meilleur estimateur :\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=10, max_features='sqrt', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=3,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=9,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "gridParam = {'n_estimators': [4, 6, 9], \n",
    "             'max_features': ['log2', 'sqrt','auto'], \n",
    "             'criterion': ['entropy', 'gini'], \n",
    "             'max_depth': [2, 3, 5, 10], \n",
    "             'min_samples_split': [2, 3, 5], \n",
    "             'min_samples_leaf': [1, 5, 8]\n",
    "            }\n",
    "\n",
    "myScoring = 'accuracy'\n",
    "\n",
    "clfGridSearchCV = GridSearchCV(estimator = RandomForestClassifier(), param_grid = gridParam, \n",
    "                               scoring = myScoring, cv = 5, n_jobs = -1, iid = True, return_train_score = True)\n",
    "\n",
    "startTime = time.time()\n",
    "clfGridSearchCV.fit(X_train, y_train)\n",
    "endTime = time.time()\n",
    "\n",
    "print(f'temps : {endTime - startTime:.2f}')\n",
    "print(f'meilleur score : {clfGridSearchCV.best_score_:.2f}')\n",
    "print(f'meilleurs paramètres :\\n{clfGridSearchCV.best_params_}')\n",
    "print(f'meilleur estimateur :\\n{clfGridSearchCV.best_estimator_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply GridSearchCV to DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temps : 35.75\n",
      "meilleur score : 0.59\n",
      "meilleurs paramètres :\n",
      "{'criterion': 'entropy', 'max_depth': 8, 'min_samples_leaf': 1}\n",
      "meilleur estimateur :\n",
      "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=8,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best')\n"
     ]
    }
   ],
   "source": [
    "gridParam = {'max_depth' : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \n",
    "             'criterion' : ['gini', 'entropy'], \n",
    "             'min_samples_leaf' : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "            }\n",
    "\n",
    "myScoring = 'accuracy'\n",
    "\n",
    "clfGridSearchCV = GridSearchCV(estimator = DecisionTreeClassifier(), param_grid = gridParam, \n",
    "                               scoring = myScoring, cv = 10, n_jobs = -1, iid = True, return_train_score = True)\n",
    "\n",
    "startTime = time.time()\n",
    "clfGridSearchCV.fit(X_train, y_train)\n",
    "endTime = time.time()\n",
    "\n",
    "print(f'temps : {endTime - startTime:.2f}')\n",
    "print(f'meilleur score : {clfGridSearchCV.best_score_:.2f}')\n",
    "print(f'meilleurs paramètres :\\n{clfGridSearchCV.best_params_}')\n",
    "print(f'meilleur estimateur :\\n{clfGridSearchCV.best_estimator_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply GridSearchCV to SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temps : 213.08\n",
      "meilleur score : 0.88\n",
      "meilleurs paramètres :\n",
      "{'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "meilleur estimateur :\n",
      "SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "gridParam = {'C' : [0.001, 0.01, 0.1, 1, 10, 100, 1000], \n",
    "             'gamma' : ['scale', 0.0001, 0.001, 0.01, 0.1, 1], \n",
    "             'kernel' : ['linear', 'poly', 'rbf']\n",
    "            }\n",
    "\n",
    "myScoring = 'accuracy'\n",
    "\n",
    "clfGridSearchCV = GridSearchCV(estimator = SVC(), param_grid = gridParam, \n",
    "                               scoring = myScoring, cv = 5, n_jobs = 1, iid = True, return_train_score = True)\n",
    "\n",
    "startTime = time.time()\n",
    "clfGridSearchCV.fit(X_train, y_train)\n",
    "endTime = time.time()\n",
    "\n",
    "print(f'temps : {endTime - startTime:.2f}')\n",
    "print(f'meilleur score : {clfGridSearchCV.best_score_:.2f}')\n",
    "print(f'meilleurs paramètres :\\n{clfGridSearchCV.best_params_}')\n",
    "print(f'meilleur estimateur :\\n{clfGridSearchCV.best_estimator_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply GridSearchCV to KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temps : 27.04\n",
      "meilleur score : 0.48\n",
      "meilleurs paramètres :\n",
      "{'metric': 'minkowski', 'n_neighbors': 1}\n",
      "meilleur estimateur :\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=1, p=2,\n",
      "                     weights='uniform')\n"
     ]
    }
   ],
   "source": [
    "gridParam = {'n_neighbors': list(range(1,15)), \n",
    "              'metric': ['minkowski', 'euclidean', 'manhattan']\n",
    "             }\n",
    "\n",
    "myScoring = 'accuracy'\n",
    "                        \n",
    "clfGridSearchCV = GridSearchCV(estimator = KNeighborsClassifier(), param_grid = gridParam, \n",
    "                               scoring = myScoring, cv = 5, n_jobs = -1, iid = True, return_train_score = True)\n",
    "\n",
    "startTime = time.time()\n",
    "clfGridSearchCV.fit(X_train, y_train)\n",
    "endTime = time.time()\n",
    "\n",
    "print(f'temps : {endTime - startTime:.2f}')\n",
    "print(f'meilleur score : {clfGridSearchCV.best_score_:.2f}')\n",
    "print(f'meilleurs paramètres :\\n{clfGridSearchCV.best_params_}')\n",
    "print(f'meilleur estimateur :\\n{clfGridSearchCV.best_estimator_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do a gridsearch taking the previous parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    'RandomForestClassifier': RandomForestClassifier(),\n",
    "    'DecisionTreeClassifier': DecisionTreeClassifier(),\n",
    "    'SVC': SVC(),\n",
    "    'KNeighborsClassifier': KNeighborsClassifier()\n",
    "}\n",
    "\n",
    "params = {\n",
    "    'RandomForestClassifier' : [\n",
    "        {'n_estimators' : [9, 6]}, \n",
    "        {'max_features' : ['auto', 'sqrt', 'log2']}, \n",
    "        {'criterion' : ['entropy', 'gini']}, \n",
    "        {'max_depth' : [10]}, \n",
    "        {'min_samples_split' : [2, 5]}, \n",
    "        {'min_samples_leaf' : [1, 5]}\n",
    "    ], \n",
    "    'DecisionTreeClassifier' : [\n",
    "        {'max_depth' : [9, 8]}, \n",
    "        {'criterion' : ['gini', 'entropy']}, \n",
    "        {'min_samples_leaf' : [1, 2, 3]}\n",
    "    ],\n",
    "    'SVC' : [\n",
    "        {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}, \n",
    "        {'gamma': ['scale', 0.0001, 0.001, 0.01, 0.1, 1]}, \n",
    "        {'kernel': ['linear', 'poly', 'rbf']}\n",
    "    ],\n",
    "    'KNeighborsClassifier' : [\n",
    "        {'metric': ['minkowski', 'manhattan']}, \n",
    "        {'n_neighbors': [1, 2]}\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Le meilleur resultat est celui du classifieur SVC :\n",
      "\tScore : 0.89\n",
      "\tDuration : 36.09\n",
      "\tParameters :\n",
      "\t\tSVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "\n",
      "Tous les résultats :\n",
      "\n",
      "\tSVC classifier :\n",
      "\tScore : 0.89\n",
      "\tDuration : 36.09\n",
      "\tParameters :\n",
      "\t\tSVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "\n",
      "\tRandomForestClassifier classifier :\n",
      "\tScore : 0.75\n",
      "\tDuration : 6.77\n",
      "\tParameters :\n",
      "\t\tRandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n",
      "\n",
      "\tDecisionTreeClassifier classifier :\n",
      "\tScore : 0.67\n",
      "\tDuration : 3.79\n",
      "\tParameters :\n",
      "\t\tDecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best')\n",
      "\n",
      "\tKNeighborsClassifier classifier :\n",
      "\tScore : 0.48\n",
      "\tDuration : 1.88\n",
      "\tParameters :\n",
      "\t\tKNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "                     weights='uniform')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class Result:\n",
    "    def __init__(self, name, score, parameters, duration):\n",
    "        self.name = name\n",
    "        self.score = score\n",
    "        self.parameters = parameters\n",
    "        self.duration = duration\n",
    "    def __repr__(self):\n",
    "        return repr((self.name, self.score, self.parameters, self.duration))\n",
    "\n",
    "results = []\n",
    "myScoring = 'accuracy'\n",
    "\n",
    "for key, value in classifiers.items():\n",
    "    clfGridSearchCV = GridSearchCV(estimator = value, param_grid = params[key], \n",
    "                                   scoring = myScoring, cv = 10, n_jobs = 1, iid = True)\n",
    "    startTime = time.time()\n",
    "    clfGridSearchCV.fit(X_train, y_train)\n",
    "    endTime = time.time()\n",
    "    result = Result(key, clfGridSearchCV.best_score_, clfGridSearchCV.best_estimator_, endTime - startTime)\n",
    "    results.append(result)\n",
    "\n",
    "results = sorted(results, key = lambda result: result.score, reverse = True)\n",
    "\n",
    "print(f'')\n",
    "print(f'Le meilleur resultat est celui du classifieur {results[0].name} :'\n",
    "      f'\\n\\tScore : {results[0].score:.2f}\\n\\tDuration : {results[0].duration:.2f}'\n",
    "      f'\\n\\tParameters :\\n\\t\\t{results[0].parameters}')\n",
    "\n",
    "print(f'\\nTous les résultats :\\n')\n",
    "for result in results:\n",
    "    print(f'\\t{result.name} classifier :\\n\\tScore : {result.score:.2f}'\n",
    "          f'\\n\\tDuration : {result.duration:.2f}\\n\\tParameters :\\n\\t\\t{result.parameters}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the best learned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(results[0].parameters, open('models/best.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reload the best model to test it with y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle chargé :\n",
      "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "\n",
      "Taille des données 502 mal classés 50\n",
      "\n",
      "Accuracy : 0.90\n",
      "\n",
      "Matrice de confusion :\n",
      "[[232  14]\n",
      " [ 36 220]]\n",
      "\n",
      "Classification report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.94      0.90       246\n",
      "         1.0       0.94      0.86      0.90       256\n",
      "\n",
      "    accuracy                           0.90       502\n",
      "   macro avg       0.90      0.90      0.90       502\n",
      "weighted avg       0.90      0.90      0.90       502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_loaded = pickle.load(open('models/best.sav', 'rb'))\n",
    "\n",
    "print(f'Modèle chargé :\\n{clf_loaded}\\n')\n",
    "\n",
    "result = clf_loaded.predict(X_test)\n",
    "\n",
    "cpt_mal_classes(y_test, result)\n",
    "\n",
    "print(f'Accuracy : {accuracy_score(result, y_test):.2f}\\n')\n",
    "print(f'Matrice de confusion :\\n{confusion_matrix(y_test, result)}\\n')\n",
    "print(f'Classification report :\\n{classification_report(y_test, result)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7569721115537849 \n",
      "\n",
      "temps d'entrainement: 0.26\n",
      "accuracy: 0.7569721115537849 \n",
      "\n",
      "matrice de confusion \n",
      " [[246   0]\n",
      " [122 134]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      1.00      0.80       246\n",
      "         1.0       1.00      0.52      0.69       256\n",
      "\n",
      "    accuracy                           0.76       502\n",
      "   macro avg       0.83      0.76      0.74       502\n",
      "weighted avg       0.84      0.76      0.74       502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "array = df.values\n",
    "X = array[:,0:-1]\n",
    "y = array[:,-1]\n",
    "\n",
    "myTrainSize = 0.3 # 30% du jeu de données pour le test\n",
    "myTestSize = 1 - myTrainSize # 70% du jeu de données pour l'entraînement\n",
    "seed = 30\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = myTrainSize, \n",
    "                                                    random_state = seed, test_size = myTestSize)\n",
    "\n",
    "pipeline = Pipeline([('scl', StandardScaler()), ('clf', SVC(gamma='scale'))])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "result = pipeline.predict(X_test)\n",
    "\n",
    "print('accuracy:',accuracy_score(result, y_test),'\\n')\n",
    "\n",
    "startTime = time.time()\n",
    "pipeline.fit(X_train, y_train)\n",
    "endTime = time.time()\n",
    "print(f'temps d\\'entrainement: {endTime - startTime:.2f}')\n",
    "\n",
    "result = pipeline.predict(X_test)\n",
    "\n",
    "print('accuracy:',accuracy_score(result, y_test),'\\n')\n",
    "conf = confusion_matrix(y_test, result)\n",
    "print ('matrice de confusion \\n',conf)\n",
    "print (classification_report(y_test, result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading pipeline & predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline chargé :\n",
      "Pipeline(memory=None,\n",
      "         steps=[('scl',\n",
      "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
      "                ('clf',\n",
      "                 SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "                     decision_function_shape='ovr', degree=3, gamma='scale',\n",
      "                     kernel='rbf', max_iter=-1, probability=False,\n",
      "                     random_state=None, shrinking=True, tol=0.001,\n",
      "                     verbose=False))],\n",
      "         verbose=False)\n",
      "\n",
      "accuracy: 0.7569721115537849 \n",
      "\n",
      "matrice de confusion \n",
      " [[246   0]\n",
      " [122 134]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      1.00      0.80       246\n",
      "         1.0       1.00      0.52      0.69       256\n",
      "\n",
      "    accuracy                           0.76       502\n",
      "   macro avg       0.83      0.76      0.74       502\n",
      "weighted avg       0.84      0.76      0.74       502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pickle.dump(pipeline, open('pipelines/thebestone.pkl', 'wb'))\n",
    "\n",
    "clf_loaded = pickle.load(open('pipelines/thebestone.pkl', 'rb'))\n",
    "print(f'Pipeline chargé :\\n{clf_loaded}\\n')\n",
    "\n",
    "result = clf_loaded.predict(X_test)\n",
    "\n",
    "print('accuracy:',accuracy_score(result, y_test),'\\n')\n",
    "conf = confusion_matrix(y_test, result)\n",
    "print ('matrice de confusion \\n',conf)\n",
    "print (classification_report(y_test, result))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
